{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Objectifs:\n",
    "#  Programmer sous R:\n",
    "#    1) Une fonction pour la (TRAIN-TEST) validation répétée\n",
    "#    2) Une fonction pour la validation croisée (K feuilles)\n",
    "#    3) Une fonction pour la validation croisée imbriquée\n",
    "#    4) Une fonction pour le Leave One Out (avec k = n)\n",
    "# \n",
    "# deux critères à valider: moyenne des performances et écart-type des \n",
    "\n",
    "# construction de modèles (ou librairies de notre choix):\n",
    "# library(rpart) = algos de décisions -> CART: classification and regression tree (classif ou regression)\n",
    "# library(MASS) = algo de décisions -> LDA : linear decision analysis: (classif binaire)\n",
    "# library(FNN) : K plus proche voisin (k-PPV)\n",
    "# tree <- rpart(X10 ~ ., data= mesData, method= 'class')  ici ~ = en fonction de et . = toutes les autres variables\n",
    "# tree <- rpart(X10 ~ ., data= mesData, method= 'class', control=rpart.control(minsplit=50), cp= val entre 0 et 1)  ici ~ = en fonction de et . = toutes les autres variables\n",
    "# predict(tree, mesNouvellesDonnées, type='class')\n",
    "# predict(tree, mesNouvellesDonnées, type='prob')\n",
    "# JEUX de données madoc: Breiman: wave5000\n",
    "\n",
    "# attente livrable: les fonctions, mini rapport explication fonction et comparaison des modèles(1,2,3,4) :robustesse sur les données de Breiman\n",
    "\n",
    "# en sortie un vecteur mélanger de 1 à n: en entré un entier\n",
    "# fonction sample déjà défini\n",
    "\n",
    "\n",
    "# Question 1\n",
    "#data = dataframe avec une colonne réel\n",
    "#k = le nombre de répétition\n",
    "#predictColumn = string = nom de la colonne X10\n",
    "library(rpart)\n",
    "validationRepeteeRPART = function (data, k) {\n",
    "  errorRate = c();\n",
    "  for (i in 1:k) {\n",
    "    #on mélange les données\n",
    "    randomData = data[sample(nrow(data)),]\n",
    "    #les 20% premières lignes sont les données de tests\n",
    "    testData = randomData[1: 1000,]\n",
    "    #les 80% autres sont les données pour la construction de modèle\n",
    "    modalData = randomData[1000:nrow(data),]\n",
    "    #on calcule la précision (le taux d'erreurs)\n",
    "    tree = rpart(modalData$X10~.,modalData, method=\"class\")\n",
    "    prediction = predict(tree, testData, type=\"class\")\n",
    "    \n",
    "    #utiliser predict pour trouver le taux d'erreur entre data et predict puis utiliser table\n",
    "    contingencyTable = table(testData$X10, prediction)\n",
    "    \n",
    "    #dans une matrice de confusion, les individus en diagonale sont les biens classés donc pour avoir le taux d'erreur on calcule la somme de tous les autres cases/la somme totale de toutes les cases\n",
    "    sumError = 0\n",
    "    total = 0\n",
    "    for (i in 1:nrow(contingencyTable)) {\n",
    "      for (j in 1:ncol(contingencyTable)) {\n",
    "        if (i != j) {\n",
    "          sumError = sumError + contingencyTable[i,j]\n",
    "        }\n",
    "        total = total + contingencyTable[i,j]\n",
    "      }\n",
    "    }\n",
    "    errorRate = c(errorRate, c(sumError/total))\n",
    "  }\n",
    "  return(mean(errorRate))\n",
    "}\n",
    "\n",
    "library(MASS)\n",
    "\n",
    "validationRepeteeLDA = function (data, k) {\n",
    "  errorRate = c()\n",
    "  for (i in 1:k) {\n",
    "    #on mélange les données\n",
    "    randomData = data[sample(nrow(data)),]\n",
    "    #les 20% premières lignes sont les données de tests\n",
    "    testData = randomData[1: 1000,]\n",
    "    #les 80% autres sont les données pour la construction de modèle\n",
    "    modalData = randomData[1000:nrow(data),]\n",
    "    #on calcule la précision (le taux d'erreurs)\n",
    "    tree = lda(modalData$X10~.,modalData, method=\"moment\")\n",
    "    prediction = predict(tree, testData, type=\"moment\")\n",
    "    #utiliser predict pour trouver le taux d'erreur entre data et predict puis utiliser table\n",
    "    contingencyTable = table(testData$X10, prediction$class)\n",
    "    #dans une matrice de confusion, les individus en diagonale sont les biens classés donc pour avoir le taux d'erreur on calcule la somme de tous les autres cases/la somme totale de toutes les cases\n",
    "    sumError = 0\n",
    "    total = 0\n",
    "    for (i in 1:nrow(contingencyTable)) {\n",
    "      for (j in 1:ncol(contingencyTable)) {\n",
    "        if (i != j) {\n",
    "          sumError = sumError + contingencyTable[i,j]\n",
    "        }\n",
    "        total = total + contingencyTable[i,j]\n",
    "      }\n",
    "    }\n",
    "    errorRate = c(errorRate, c(sumError/total))\n",
    "  }\n",
    "  return(mean(errorRate))\n",
    "}\n",
    "\n",
    "#Exercice 2\n",
    "#data = dataframe\n",
    "#partitions = integer\n",
    "validationCroiseeRPART = function(data, partitions, metric) {\n",
    "  errorRate = c()\n",
    "  #on mélange les données\n",
    "  randomData = data[sample(nrow(data)),]\n",
    "  #list\n",
    "  setPartitions = split(randomData, 1:partitions)\n",
    "  for (i in 1:(partitions)) {\n",
    "    tempSetPartitions = setPartitions\n",
    "    currentTestData = setPartitions[[i]]\n",
    "    currentModalDataList = tempSetPartitions[-i]\n",
    "    #fusion dataframe\n",
    "    currentModalData = rbind.data.frame(currentModalDataList[[1]], currentModalDataList[[2]])\n",
    "    \n",
    "    for (j in 3:(partitions-1)) {\n",
    "      currentModalData = rbind.data.frame(currentModalData, currentModalDataList[[j]])\n",
    "    }\n",
    "    \n",
    "    numOfLinesTestCurrentModalData = as.integer(length(currentModalData)*0.2)\n",
    "    numOflinesModalCurrentModalData = as.integer(length(currentModalData)*0.8)\n",
    "    \n",
    "    testData_step2 = currentModalData[1:numOfLinesTestCurrentModalData,]\n",
    "    modalData_step2 = currentModalData[numOfLinesTestCurrentModalData+1:numOflinesModalCurrentModalData,]\n",
    "    \n",
    "    #on calcule la précision (le taux d'erreurs)\n",
    "    tree = rpart(modalData_step2$X10~.,modalData_step2, method=\"class\")\n",
    "    prediction = predict(tree, testData_step2, type=\"class\")\n",
    "    #utiliser predict pour trouver le taux d'erreur entre data et predict puis utiliser table\n",
    "    contingencyTable = table(testData_step2$X10, prediction)\n",
    "    \n",
    "    total = 0\n",
    "    sumError = 0\n",
    "    for (i in 1:nrow(contingencyTable)) {\n",
    "      for (j in 1:ncol(contingencyTable)) {\n",
    "        if (i != j) {\n",
    "          sumError = sumError + contingencyTable[i,j]\n",
    "        }\n",
    "        total = total + contingencyTable[i,j]\n",
    "      }\n",
    "    }\n",
    "    errorRate = c(errorRate, c(sumError/total))\n",
    "    \n",
    "  }\n",
    "  \n",
    "  meanPrecision = mean(errorRate)\n",
    "  robustesse_calculate = 0\n",
    "  \n",
    "  for (i in 1:length(errorRate)) {\n",
    "    robustesse_calculate = robustesse_calculate + (errorRate[i] - meanPrecision)*(errorRate[i] - meanPrecision)\n",
    "  }\n",
    "  #nombre de valeurs dans error rate est la même que le nombre de partitions\n",
    "  robustesse = robustesse_calculate/length(errorRate)\n",
    "  \n",
    "  if (metric == 1) {\n",
    "    return(robustesse)\n",
    "  } else {\n",
    "    return(mean(errorRate))\n",
    "  }\n",
    "  \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "validationCroiseeLDA = function(data, partitions, metric) {\n",
    "  errorRate = c()\n",
    "  #on mélange les données\n",
    "  randomData = data[sample(nrow(data)),]\n",
    "  #list\n",
    "  setPartitions = split(randomData, 1:partitions)\n",
    "  for (i in 1:(partitions)) {\n",
    "    tempSetPartitions = setPartitions\n",
    "    currentTestData = setPartitions[[i]]\n",
    "    currentModalDataList = tempSetPartitions[-i]\n",
    "    #fusion dataframe\n",
    "    currentModalData = rbind.data.frame(currentModalDataList[[1]], currentModalDataList[[2]])\n",
    "    \n",
    "    for (j in 3:(partitions-1)) {\n",
    "      currentModalData = rbind.data.frame(currentModalData, currentModalDataList[[j]])\n",
    "    }\n",
    "    \n",
    "    numOfLinesTestCurrentModalData = as.integer(length(currentModalData)*0.2)\n",
    "    numOflinesModalCurrentModalData = as.integer(length(currentModalData)*0.8)\n",
    "    \n",
    "    testData_step2 = currentModalData[1:numOfLinesTestCurrentModalData,]\n",
    "    modalData_step2 = currentModalData[numOfLinesTestCurrentModalData+1:numOflinesModalCurrentModalData,]\n",
    "    \n",
    "    #on calcule la précision (le taux d'erreurs)\n",
    "    tree = lda(X10~.,modalData_step2)\n",
    "    prediction = predict(tree, testData_step2, type=\"class\")\n",
    "    #utiliser predict pour trouver le taux d'erreur entre data et predict puis utiliser table\n",
    "    contingencyTable = table(testData_step2$X10, prediction$class)\n",
    "    \n",
    "    total = 0\n",
    "    sumError = 0\n",
    "    for (i in 1:nrow(contingencyTable)) {\n",
    "      for (j in 1:ncol(contingencyTable)) {\n",
    "        if (i != j) {\n",
    "          sumError = sumError + contingencyTable[i,j]\n",
    "        }\n",
    "        total = total + contingencyTable[i,j]\n",
    "      }\n",
    "    }\n",
    "    errorRate = c(errorRate, c(sumError/total))\n",
    "    \n",
    "  }\n",
    "  \n",
    "  meanPrecision = mean(errorRate)\n",
    "  robustesse_calculate = 0\n",
    "  \n",
    "  for (i in 1:length(errorRate)) {\n",
    "    robustesse_calculate = robustesse_calculate + (errorRate[i] - meanPrecision)*(errorRate[i] - meanPrecision)\n",
    "  }\n",
    "  #nombre de valeurs dans error rate est la même que le nombre de partitions\n",
    "  robustesse = robustesse_calculate/length(errorRate)\n",
    "  \n",
    "  if (metric == 1) {\n",
    "    return(robustesse)\n",
    "  } else {\n",
    "    return(mean(errorRate))\n",
    "  }\n",
    "  \n",
    "}\n",
    "\n",
    "\n",
    "#appel de fonction validationCroisee défini précédemment\n",
    "#en paramètre k = le nombre de répétition\n",
    "validationCroiseeRepetee = function (data, partitions, k) {\n",
    "  robustesseMean = 0\n",
    "  errorRateMean = 0\n",
    "  \n",
    "  for (i in 1:k) {\n",
    "    robustesseMean = robustesseMean + validationCroiseeRPART(data, partitions, 1)\n",
    "    errorRateMean = errorRateMean + validationCroiseeRPART(data, partitions, 0)\n",
    "  }\n",
    "  \n",
    "  robustesseMean = robustesseMean/k\n",
    "  errorRateMean = errorRateMean/k\n",
    "  \n",
    "  return(c(robustesseMean, errorRateMean))\n",
    "  \n",
    "}\n",
    "\n",
    "#data = dataframe\n",
    "#partitions = nombre de partition où on va split le dataset\n",
    "validationCroiseeImpliquee = function(data, partitions) {\n",
    "  \n",
    "  errorRate = c()\n",
    "  #on mélange les données\n",
    "  randomData = data[sample(nrow(data)),]\n",
    "  #list\n",
    "  setPartitions = split(randomData, 1:partitions)\n",
    "  listErrorRate = c()\n",
    "  \n",
    "  for (i in 1:partitions) {\n",
    "    \n",
    "    errorRate = c()\n",
    "    \n",
    "    for (i in 1:partitions-1) {\n",
    " \n",
    "      tempSetPartitions = setPartitions\n",
    "      currentTestData = setPartitions[[i]]\n",
    "      currentModalDataList = tempSetPartitions[-i]\n",
    "      #fusion dataframe\n",
    "      currentModalData = rbind.data.frame(currentModalDataList[[1]], currentModalDataList[[2]])\n",
    "      \n",
    "      for (j in 3:(partitions-2)) {\n",
    "        currentModalData = rbind.data.frame(currentModalData, currentModalDataList[[j]])\n",
    "      }\n",
    "      \n",
    "      numOfLinesTestCurrentModalData = as.integer(length(currentModalData)*0.2)\n",
    "      numOflinesModalCurrentModalData = as.integer(length(currentModalData)*0.8)\n",
    "      \n",
    "      testData_step2 = currentModalData[1:numOfLinesTestCurrentModalData,]\n",
    "      modalData_step2 = currentModalData[numOfLinesTestCurrentModalData+1:numOflinesModalCurrentModalData,]\n",
    "      \n",
    "      #on calcule la précision (le taux d'erreurs)\n",
    "      tree = lda(X10~.,modalData_step2)\n",
    "      prediction = predict(tree, testData_step2, type=\"class\")\n",
    "      #utiliser predict pour trouver le taux d'erreur entre data et predict puis utiliser table\n",
    "      contingencyTable = table(testData_step2$X10, prediction$class)\n",
    "      \n",
    "      total = 0\n",
    "      sumError = 0\n",
    "      for (i in 1:nrow(contingencyTable)) {\n",
    "        for (j in 1:ncol(contingencyTable)) {\n",
    "          if (i != j) {\n",
    "            sumError = sumError + contingencyTable[i,j]\n",
    "          }\n",
    "          total = total + contingencyTable[i,j]\n",
    "        }\n",
    "      }\n",
    "      errorRate = c(errorRate, c(sumError/total))\n",
    "    }\n",
    "    \n",
    "    listErrorRate = c(c(listErrorRate), mean(errorRate))\n",
    "    \n",
    "  }\n",
    "  \n",
    "  return(listErrorRate)\n",
    "  \n",
    "}\n",
    "\n",
    "#appel de la fonction validationCroisee\n",
    "#en paramètre data: un dataframe\n",
    "leaveOneOut = function(data) {\n",
    "  numberOfrows = nrow(data)\n",
    "  return(c(validationCroiseeRPART(data, numberOfrows, 0), validationCroiseeRPART(data, numberOfrows, 1)))\n",
    "}\n",
    "\n",
    "\n",
    "#appel de tous les fonctions définies précédemment\n",
    "\n",
    "algorithmSelection = function(data, K) {\n",
    "  \n",
    "  validationCroiseeRPARTErrorRate = validationRepeteeLDA(data, K)\n",
    "  validationCroiseeLDAErrorRate = validationRepeteeRPART(data, K)\n",
    "  \n",
    "  if (validationCroiseeRPARTErrorRate > validationCroiseeLDAErrorRate) {\n",
    "    return(\"SOLUTION: LDA\")\n",
    "  } else {\n",
    "    return(\"SOLUTION: RPART\")\n",
    "  }\n",
    "  \n",
    "  return(\"ERROR\")\n",
    "}\n",
    "\n",
    "validationCroiseeGetModel = function(data, partitions, colonneCible) {\n",
    "  errorRate = c()\n",
    "  #on m\\u{fffd}lange les donn\\u{fffd}es\n",
    "  randomData = data[sample(nrow(data)),]\n",
    "  #list\n",
    "  setPartitions = split(randomData, 1:partitions)\n",
    "  for (i in 1:(partitions)) {\n",
    "    tempSetPartitions = setPartitions\n",
    "    currentTestData = setPartitions[[i]]\n",
    "    currentModalDataList = tempSetPartitions[-i]\n",
    "    #fusion dataframe\n",
    "    currentModalData = rbind.data.frame(currentModalDataList[[1]], currentModalDataList[[2]])\n",
    "    \n",
    "    for (j in 3:(partitions-1)) {\n",
    "      currentModalData = rbind.data.frame(currentModalData, currentModalDataList[[j]])\n",
    "    }\n",
    "    \n",
    "    numOfLinesTestCurrentModalData = as.integer(length(currentModalData)*0.2)\n",
    "    numOflinesModalCurrentModalData = as.integer(length(currentModalData)*0.8)\n",
    "    \n",
    "    testData_step2 = currentModalData[1:numOfLinesTestCurrentModalData,]\n",
    "    modalData_step2 = currentModalData[numOfLinesTestCurrentModalData+1:numOflinesModalCurrentModalData,]\n",
    "    \n",
    "    #on calcule la pr\\u{fffd}cision (le taux d'erreurs)\n",
    "    tree = rpart(modalData_step2$X1~.,modalData_step2, method=\"class\",control=rpart.control(minsplit=5,cp=0))\n",
    "    prediction = predict(tree, testData_step2, type=\"class\")\n",
    "    #utiliser predict pour trouver le taux d'erreur entre data et predict puis utiliser table\n",
    "    contingencyTable = table(testData_step2$X1, prediction)\n",
    "    \n",
    "    total = 0\n",
    "    sumError = 0\n",
    "    for (i in 1:nrow(contingencyTable)) {\n",
    "      for (j in 1:ncol(contingencyTable)) {\n",
    "        if (i != j) {\n",
    "          sumError = sumError + contingencyTable[i,j]\n",
    "        }\n",
    "        total = total + contingencyTable[i,j]\n",
    "      }\n",
    "    }\n",
    "    errorRate = c(errorRate, c(sumError/total))\n",
    "    \n",
    "  }\n",
    "  \n",
    "  meanPrecision = mean(errorRate)\n",
    "  robustesse_calculate = 0\n",
    "  \n",
    "  for (i in 1:length(errorRate)) {\n",
    "    robustesse_calculate = robustesse_calculate + (errorRate[i] - meanPrecision)*(errorRate[i] - meanPrecision)\n",
    "  }\n",
    "  #nombre de valeurs dans error rate est la m\\u{fffd}me que le nombre de partitions\n",
    "  robustesse = robustesse_calculate/length(errorRate)\n",
    "  \n",
    "  if (mean(errorRate) <= 0.3) {\n",
    "    listResult = list(mean(errorRate), tree)\n",
    "    print(\"Error Rate < 0.3\")\n",
    "    print(mean(errorRate))\n",
    "    return(listResult)\n",
    "  }else{\n",
    "    listResult = list(0, tree)\n",
    "    print(\"Error Rate > 0.3, WRONG MODEL\")\n",
    "    print(listResult)\n",
    "    return(listResult)\n",
    "  }\n",
    "}\n",
    "\n",
    "\n",
    "loopGetModel = function(data, partitions){\n",
    "  result = 0\n",
    "  while(result == 0){\n",
    "    print(\"generating new model ...\")\n",
    "    #Variable cible : predictionCA\n",
    "    donneesAppr = data[ , -c(1,2,3,4,5,6,7,8,9)]\n",
    "    names(donneesAppr) = c(\"X1\",\"X2\",\"X3\",\"X4\",\"X5\",\"X6\",\"X7\",\"X8\",\"X9\",\"X10\",\"X11\",\"X12\",\"X13\",\"X14\",\"X15\",\"X16\",\"X17\",\"X18\",\"X19\",\"X20\",\"X21\",\"X22\",\"X23\",\"X24\",\"X25\",\"X26\",\"X27\",\"X28\",\"X29\",\"X30\",\"X31\")\n",
    "    listResult = validationCroiseeGetModel(donneesAppr, partitions, \"X10\")\n",
    "    result = listResult[[1]]\n",
    "  }\n",
    "  print(listResult)\n",
    "  \n",
    "  \n",
    "  donneesTest = test[ , -c(1,2,3,36,37,38,39)]\n",
    "  names(donneesTest) = c(\"X2\",\"X3\",\"X4\",\"X5\",\"X6\",\"X7\",\"X8\",\"X9\",\"X10\",\"X11\",\"X12\",\"X13\",\"X14\",\"X15\",\"X16\",\"X17\",\"X18\",\"X19\",\"X20\",\"X21\",\"X22\",\"X23\",\"X24\",\"X25\",\"X26\",\"X27\",\"X28\",\"X29\",\"X30\",\"X31\")\n",
    "  prediction = predict(listResult[[2]], donneesTest, type=\"class\")\n",
    "  print(prediction)\n",
    "\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"generating new model ...\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in split.default(x = seq_len(nrow(x)), f = f, drop = drop, ...):\n",
      "\"la taille de données n'est pas un multiple de la variable découpée\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Error Rate > 0.3, WRONG MODEL\"\n",
      "[[1]]\n",
      "[1] 0\n",
      "\n",
      "[[2]]\n",
      "n= 25 \n",
      "\n",
      "node), split, n, loss, yval, (yprob)\n",
      "      * denotes terminal node\n",
      "\n",
      "  1) root 25 16 0 (0.36 0.04 0.08 0.04 0.08 0.08 0.04 0.04 0.04 0.08 0.04 0.04 0.04)  \n",
      "    2) X2< 0.5 9  0 0 (1 0 0 0 0 0 0 0 0 0 0 0 0) *\n",
      "    3) X2>=0.5 16 14 22400 (0 0.062 0.12 0.062 0.12 0.12 0.062 0.062 0.062 0.12 0.062 0.062 0.062)  \n",
      "      6) X6< 4215.835 14 12 22400 (0 0.071 0.14 0.071 0.14 0.14 0.071 0.071 0.071 0 0.071 0.071 0.071)  \n",
      "       12) X6>=1615.28 2  0 44800 (0 0 0 0 0 1 0 0 0 0 0 0 0) *\n",
      "       13) X6< 1615.28 12 10 22400 (0 0.083 0.17 0.083 0.17 0 0.083 0.083 0.083 0 0.083 0.083 0.083)  \n",
      "         26) X18>=290.73 3  1 42400 (0 0 0 0 0.67 0 0 0 0.33 0 0 0 0) *\n",
      "         27) X18< 290.73 9  7 22400 (0 0.11 0.22 0.11 0 0 0.11 0.11 0 0 0.11 0.11 0.11)  \n",
      "           54) X2< 1.5 3  1 22400 (0 0.33 0.67 0 0 0 0 0 0 0 0 0 0) *\n",
      "           55) X2>=1.5 6  5 40400 (0 0 0 0.17 0 0 0.17 0.17 0 0 0.17 0.17 0.17)  \n",
      "            110) X2< 3.5 2  1 40400 (0 0 0 0.5 0 0 0.5 0 0 0 0 0 0) *\n",
      "            111) X2>=3.5 4  3 70000 (0 0 0 0 0 0 0 0.25 0 0 0.25 0.25 0.25) *\n",
      "      7) X6>=4215.835 2  0 134400 (0 0 0 0 0 0 0 0 0 1 0 0 0) *\n",
      "\n",
      "[1] \"generating new model ...\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in split.default(x = seq_len(nrow(x)), f = f, drop = drop, ...):\n",
      "\"la taille de données n'est pas un multiple de la variable découpée\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Error Rate > 0.3, WRONG MODEL\"\n",
      "[[1]]\n",
      "[1] 0\n",
      "\n",
      "[[2]]\n",
      "n= 25 \n",
      "\n",
      "node), split, n, loss, yval, (yprob)\n",
      "      * denotes terminal node\n",
      "\n",
      " 1) root 25 16 0 (0.36 0.16 0.04 0.04 0.12 0.04 0.04 0.04 0.04 0.04 0.04 0.04)  \n",
      "   2) X2< 0.5 9  0 0 (1 0 0 0 0 0 0 0 0 0 0 0) *\n",
      "   3) X2>=0.5 16 12 17500 (0 0.25 0.062 0.062 0.19 0.062 0.062 0.062 0.062 0.062 0.062 0.062)  \n",
      "     6) X20< 78.985 9  5 17500 (0 0.44 0.11 0.11 0 0 0.11 0.11 0 0.11 0 0)  \n",
      "      12) X3>=882.875 4  0 17500 (0 1 0 0 0 0 0 0 0 0 0 0) *\n",
      "      13) X3< 882.875 5  4 20000 (0 0 0.2 0.2 0 0 0.2 0.2 0 0.2 0 0)  \n",
      "        26) X2< 1.5 2  1 20000 (0 0 0.5 0.5 0 0 0 0 0 0 0 0) *\n",
      "        27) X2>=1.5 3  2 38400 (0 0 0 0 0 0 0.33 0.33 0 0.33 0 0) *\n",
      "     7) X20>=78.985 7  4 22400 (0 0 0 0 0.43 0.14 0 0 0.14 0 0.14 0.14)  \n",
      "      14) X2< 1.5 3  0 22400 (0 0 0 0 1 0 0 0 0 0 0 0) *\n",
      "      15) X2>=1.5 4  3 35000 (0 0 0 0 0 0.25 0 0 0.25 0 0.25 0.25) *\n",
      "\n",
      "[1] \"generating new model ...\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in split.default(x = seq_len(nrow(x)), f = f, drop = drop, ...):\n",
      "\"la taille de données n'est pas un multiple de la variable découpée\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Error Rate > 0.3, WRONG MODEL\"\n",
      "[[1]]\n",
      "[1] 0\n",
      "\n",
      "[[2]]\n",
      "n= 25 \n",
      "\n",
      "node), split, n, loss, yval, (yprob)\n",
      "      * denotes terminal node\n",
      "\n",
      " 1) root 25 16 0 (0.36 0.2 0.04 0.08 0.04 0.08 0.04 0.04 0.04 0.04 0.04)  \n",
      "   2) X2< 0.5 9  0 0 (1 0 0 0 0 0 0 0 0 0 0) *\n",
      "   3) X2>=0.5 16 11 17500 (0 0.31 0.062 0.12 0.062 0.12 0.062 0.062 0.062 0.062 0.062)  \n",
      "     6) X2< 1.5 8  3 17500 (0 0.62 0.12 0.25 0 0 0 0 0 0 0)  \n",
      "      12) X5< 1104.47 5  0 17500 (0 1 0 0 0 0 0 0 0 0 0) *\n",
      "      13) X5>=1104.47 3  1 22400 (0 0 0.33 0.67 0 0 0 0 0 0 0) *\n",
      "     7) X2>=1.5 8  6 44800 (0 0 0 0 0.12 0.25 0.12 0.12 0.12 0.12 0.12)  \n",
      "      14) X6>=7415.715 2  0 44800 (0 0 0 0 0 1 0 0 0 0 0) *\n",
      "      15) X6< 7415.715 6  5 35000 (0 0 0 0 0.17 0 0.17 0.17 0.17 0.17 0.17)  \n",
      "        30) X5< 2506.75 4  3 35000 (0 0 0 0 0.25 0 0.25 0.25 0 0 0.25) *\n",
      "        31) X5>=2506.75 2  1 105000 (0 0 0 0 0 0 0 0 0.5 0.5 0) *\n",
      "\n",
      "[1] \"generating new model ...\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in split.default(x = seq_len(nrow(x)), f = f, drop = drop, ...):\n",
      "\"la taille de données n'est pas un multiple de la variable découpée\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Error Rate > 0.3, WRONG MODEL\"\n",
      "[[1]]\n",
      "[1] 0\n",
      "\n",
      "[[2]]\n",
      "n= 25 \n",
      "\n",
      "node), split, n, loss, yval, (yprob)\n",
      "      * denotes terminal node\n",
      "\n",
      " 1) root 25 16 0 (0.36 0.08 0.04 0.04 0.08 0.04 0.08 0.04 0.04 0.08 0.04 0.04 0.04)  \n",
      "   2) X2< 0.5 9  0 0 (1 0 0 0 0 0 0 0 0 0 0 0 0) *\n",
      "   3) X2>=0.5 16 14 17500 (0 0.12 0.062 0.062 0.12 0.062 0.12 0.062 0.062 0.12 0.062 0.062 0.062)  \n",
      "     6) X22< 3250.565 11  9 17500 (0 0.18 0.091 0.091 0.18 0.091 0 0.091 0.091 0 0.091 0.091 0)  \n",
      "      12) X6< 29.15 3  1 22400 (0 0 0 0 0.67 0.33 0 0 0 0 0 0 0) *\n",
      "      13) X6>=29.15 8  6 17500 (0 0.25 0.12 0.12 0 0 0 0.12 0.12 0 0.12 0.12 0)  \n",
      "        26) X26< 6.43 2  0 17500 (0 1 0 0 0 0 0 0 0 0 0 0 0) *\n",
      "        27) X26>=6.43 6  5 20000 (0 0 0.17 0.17 0 0 0 0.17 0.17 0 0.17 0.17 0)  \n",
      "          54) X2< 1.5 2  1 20000 (0 0 0.5 0.5 0 0 0 0 0 0 0 0 0) *\n",
      "          55) X2>=1.5 4  3 42400 (0 0 0 0 0 0 0 0.25 0.25 0 0.25 0.25 0) *\n",
      "     7) X22>=3250.565 5  3 35000 (0 0 0 0 0 0 0.4 0 0 0.4 0 0 0.2)  \n",
      "      14) X2< 3.5 2  0 35000 (0 0 0 0 0 0 1 0 0 0 0 0 0) *\n",
      "      15) X2>=3.5 3  1 87500 (0 0 0 0 0 0 0 0 0 0.67 0 0 0.33) *\n",
      "\n",
      "[1] \"generating new model ...\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in split.default(x = seq_len(nrow(x)), f = f, drop = drop, ...):\n",
      "\"la taille de données n'est pas un multiple de la variable découpée\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Error Rate > 0.3, WRONG MODEL\"\n",
      "[[1]]\n",
      "[1] 0\n",
      "\n",
      "[[2]]\n",
      "n= 25 \n",
      "\n",
      "node), split, n, loss, yval, (yprob)\n",
      "      * denotes terminal node\n",
      "\n",
      "  1) root 25 19 0 (0.24 0.04 0.12 0.08 0.12 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04)  \n",
      "    2) X2< 0.5 6  0 0 (1 0 0 0 0 0 0 0 0 0 0 0 0 0 0) *\n",
      "    3) X2>=0.5 19 16 19200 (0 0.053 0.16 0.11 0.16 0.053 0.053 0.053 0.053 0.053 0.053 0.053 0.053 0.053 0.053)  \n",
      "      6) X6>=4494.395 2  0 22400 (0 0 0 0 1 0 0 0 0 0 0 0 0 0 0) *\n",
      "      7) X6< 4494.395 17 14 19200 (0 0.059 0.18 0.12 0.059 0.059 0.059 0.059 0.059 0.059 0.059 0.059 0.059 0.059 0.059)  \n",
      "       14) X28< 9.15 5  2 19200 (0 0 0.6 0 0 0 0 0.2 0 0 0 0.2 0 0 0)  \n",
      "         28) X2< 1.5 3  0 19200 (0 0 1 0 0 0 0 0 0 0 0 0 0 0 0) *\n",
      "         29) X2>=1.5 2  1 52500 (0 0 0 0 0 0 0 0.5 0 0 0 0.5 0 0 0) *\n",
      "       15) X28>=9.15 12 10 20200 (0 0.083 0 0.17 0.083 0.083 0.083 0 0.083 0.083 0.083 0 0.083 0.083 0.083)  \n",
      "         30) X15>=9159.845 3  1 20200 (0 0 0 0.67 0 0 0 0 0 0 0.33 0 0 0 0) *\n",
      "         31) X15< 9159.845 9  8 17500 (0 0.11 0 0 0.11 0.11 0.11 0 0.11 0.11 0 0 0.11 0.11 0.11)  \n",
      "           62) X2< 1.5 3  2 17500 (0 0.33 0 0 0.33 0.33 0 0 0 0 0 0 0 0 0) *\n",
      "           63) X2>=1.5 6  5 42400 (0 0 0 0 0 0 0.17 0 0.17 0.17 0 0 0.17 0.17 0.17)  \n",
      "            126) X2< 3 2  1 42400 (0 0 0 0 0 0 0.5 0 0.5 0 0 0 0 0 0) *\n",
      "            127) X2>=3 4  3 80000 (0 0 0 0 0 0 0 0 0 0.25 0 0 0.25 0.25 0.25) *\n",
      "\n",
      "[1] \"generating new model ...\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in split.default(x = seq_len(nrow(x)), f = f, drop = drop, ...):\n",
      "\"la taille de données n'est pas un multiple de la variable découpée\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Error Rate > 0.3, WRONG MODEL\"\n",
      "[[1]]\n",
      "[1] 0\n",
      "\n",
      "[[2]]\n",
      "n= 25 \n",
      "\n",
      "node), split, n, loss, yval, (yprob)\n",
      "      * denotes terminal node\n",
      "\n",
      " 1) root 25 14 0 (0.44 0.04 0.04 0.04 0.16 0.04 0.04 0.04 0.04 0.04 0.04 0.04)  \n",
      "   2) X2< 0.5 11  0 0 (1 0 0 0 0 0 0 0 0 0 0 0) *\n",
      "   3) X2>=0.5 14 10 22400 (0 0.071 0.071 0.071 0.29 0.071 0.071 0.071 0.071 0.071 0.071 0.071)  \n",
      "     6) X18>=46.735 7  3 22400 (0 0 0.14 0 0.57 0 0.14 0 0 0 0.14 0)  \n",
      "      12) X13< 0.885 4  0 22400 (0 0 0 0 1 0 0 0 0 0 0 0) *\n",
      "      13) X13>=0.885 3  2 20000 (0 0 0.33 0 0 0 0.33 0 0 0 0.33 0) *\n",
      "     7) X18< 46.735 7  6 10600 (0 0.14 0 0.14 0 0.14 0 0.14 0.14 0.14 0 0.14)  \n",
      "      14) X2< 1.5 2  1 10600 (0 0.5 0 0.5 0 0 0 0 0 0 0 0) *\n",
      "      15) X2>=1.5 5  4 35000 (0 0 0 0 0 0.2 0 0.2 0.2 0.2 0 0.2)  \n",
      "        30) X2< 4.5 2  1 35000 (0 0 0 0 0 0.5 0 0.5 0 0 0 0) *\n",
      "        31) X2>=4.5 3  2 87500 (0 0 0 0 0 0 0 0 0.33 0.33 0 0.33) *\n",
      "\n",
      "[1] \"generating new model ...\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in split.default(x = seq_len(nrow(x)), f = f, drop = drop, ...):\n",
      "\"la taille de données n'est pas un multiple de la variable découpée\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Error Rate < 0.3\"\n",
      "[1] 0.2\n",
      "[[1]]\n",
      "[1] 0.2\n",
      "\n",
      "[[2]]\n",
      "n= 25 \n",
      "\n",
      "node), split, n, loss, yval, (yprob)\n",
      "      * denotes terminal node\n",
      "\n",
      " 1) root 25 15 0 (0.4 0.12 0.04 0.04 0.04 0.08 0.04 0.04 0.08 0.04 0.04 0.04)  \n",
      "   2) X2< 0.5 10  0 0 (1 0 0 0 0 0 0 0 0 0 0 0) *\n",
      "   3) X2>=0.5 15 12 17500 (0 0.2 0.067 0.067 0.067 0.13 0.067 0.067 0.13 0.067 0.067 0.067)  \n",
      "     6) X26< 35.21 4  1 17500 (0 0.75 0 0 0 0 0 0 0 0 0.25 0) *\n",
      "     7) X26>=35.21 11  9 35000 (0 0 0.091 0.091 0.091 0.18 0.091 0.091 0.18 0.091 0 0.091)  \n",
      "      14) X4>=1361.99 2  0 35000 (0 0 0 0 0 1 0 0 0 0 0 0) *\n",
      "      15) X4< 1361.99 9  7 87500 (0 0 0.11 0.11 0.11 0 0.11 0.11 0.22 0.11 0 0.11)  \n",
      "        30) X2< 4.5 6  5 20000 (0 0 0.17 0.17 0.17 0 0.17 0.17 0 0.17 0 0)  \n",
      "          60) X2< 3 4  3 20000 (0 0 0.25 0.25 0.25 0 0.25 0 0 0 0 0) *\n",
      "          61) X2>=3 2  1 80000 (0 0 0 0 0 0 0 0.5 0 0.5 0 0) *\n",
      "        31) X2>=4.5 3  1 87500 (0 0 0 0 0 0 0 0 0.67 0 0 0.33) *\n",
      "\n",
      "    1     2     3     4     5     6     7     8     9    10    11    12    13 \n",
      "    0 35000 35000 17500     0 20000 80000     0 17500 20000 17500 17500 35000 \n",
      "   14    15    16    17    18    19    20    21    22    23    24    25    26 \n",
      "20000 17500     0 35000 17500 87500 17500 17500 17500 17500     0     0     0 \n",
      "   27    28    29    30    31    32    33    34    35    36    37    38    39 \n",
      "35000     0 17500 20000 80000 35000 17500 20000 17500 20000 17500 17500 87500 \n",
      "   40    41    42    43    44    45    46    47    48    49    50    51    52 \n",
      "17500 17500 17500 17500 35000 17500 20000 17500 20000 35000 17500 17500 17500 \n",
      "   53    54    55    56    57    58    59    60    61    62    63    64    65 \n",
      "17500 17500 17500 17500 35000     0 87500 35000 17500     0     0 87500 87500 \n",
      "   66    67    68    69    70    71    72    73    74    75    76    77    78 \n",
      "    0 17500 35000 20000 20000 17500 17500     0 87500     0     0     0     0 \n",
      "   79    80    81    82    83    84    85    86    87    88    89    90    91 \n",
      "    0     0     0     0     0     0     0     0     0 17500     0 17500 87500 \n",
      "   92    93    94    95    96    97    98    99   100   101   102   103   104 \n",
      "35000     0 35000 17500 87500 80000 17500 80000     0 35000 87500 35000 17500 \n",
      "  105   106   107   108   109   110   111   112   113   114   115   116   117 \n",
      "17500     0     0 20000 35000 20000 17500 35000     0 20000     0 35000 17500 \n",
      "  118   119   120   121   122   123   124   125   126   127   128   129   130 \n",
      "17500     0     0 35000 35000     0 17500     0     0 20000 20000 17500 35000 \n",
      "  131   132   133   134   135   136   137   138   139   140   141   142   143 \n",
      "17500 20000 17500 17500 20000 87500 17500 17500 35000 87500 17500 17500     0 \n",
      "  144   145   146   147   148   149   150   151   152   153   154   155   156 \n",
      "    0 17500 87500 87500 17500 20000 17500 87500 87500 20000 17500     0 17500 \n",
      "  157   158   159   160   161   162   163   164   165   166   167   168   169 \n",
      "87500 87500 35000 20000 17500     0 35000 87500     0     0     0     0     0 \n",
      "  170   171   172   173   174   175   176   177   178   179   180   181   182 \n",
      "87500 80000     0     0     0     0     0 17500     0     0     0     0 35000 \n",
      "  183   184   185   186   187   188   189   190   191   192   193   194   195 \n",
      "    0 20000     0 87500 17500 35000 17500 17500 35000 87500 17500 17500 80000 \n",
      "  196   197   198   199   200   201   202   203   204   205   206   207   208 \n",
      "    0 80000     0 35000 17500 20000     0     0 20000 35000 80000 17500 20000 \n",
      "  209   210   211   212   213   214   215   216   217   218   219   220   221 \n",
      "    0     0     0     0     0 87500 17500 17500     0 17500     0 35000 17500 \n",
      "  222   223   224   225   226   227   228   229   230   231   232   233   234 \n",
      "35000 20000 80000     0 17500 80000 20000     0 80000 20000 20000 17500 17500 \n",
      "  235   236   237   238   239   240   241   242   243   244   245   246   247 \n",
      "17500 17500 20000     0     0     0 17500 17500 17500     0     0     0     0 \n",
      "  248   249   250   251   252   253   254   255   256   257   258   259   260 \n",
      "    0 17500 35000     0     0     0     0 87500 87500 17500     0 17500 17500 \n",
      "  261   262   263   264   265   266   267   268   269   270   271   272   273 \n",
      "17500 17500     0 87500 17500     0     0 20000 17500 17500 17500 17500 80000 \n",
      "  274   275   276   277   278   279   280   281   282   283   284   285   286 \n",
      "    0     0     0     0 20000     0     0     0     0 80000 20000 87500 35000 \n",
      "  287   288   289   290   291   292   293   294   295   296   297   298   299 \n",
      "    0     0 20000 87500 35000 20000 20000     0 35000     0 17500     0 35000 \n",
      "  300   301   302   303   304   305   306   307   308   309   310   311   312 \n",
      "    0 17500 17500 17500 87500     0 20000     0 20000     0 20000     0 35000 \n",
      "  313   314   315   316   317   318   319   320   321   322   323   324   325 \n",
      "    0 17500     0     0     0 80000 87500     0     0     0 17500 17500     0 \n",
      "  326   327   328   329   330   331   332   333   334   335   336   337   338 \n",
      "17500 80000 17500 87500 35000     0 17500     0 17500 87500     0     0 20000 \n",
      "  339   340   341   342   343   344   345   346   347   348   349   350   351 \n",
      "87500 17500 17500     0 20000 17500 80000 87500 87500 17500 87500 87500 20000 \n",
      "  352   353   354   355   356   357   358   359   360   361   362   363   364 \n",
      "20000     0 17500 17500 17500 87500     0 35000 87500 17500 20000 17500 87500 \n",
      "  365   366   367   368   369   370   371   372   373   374   375   376   377 \n",
      "17500 80000 87500     0 17500 17500     0     0 35000     0 87500 20000 20000 \n",
      "  378   379   380   381   382   383   384   385   386   387   388   389   390 \n",
      "    0     0 20000 20000 20000 87500 20000 35000 87500     0     0     0     0 \n",
      "  391   392   393   394   395   396   397   398   399   400   401   402   403 \n",
      "    0     0     0     0     0     0     0     0 17500 17500 35000 17500     0 \n",
      "  404   405   406   407   408   409   410   411   412   413   414   415   416 \n",
      "17500 17500 17500 80000 17500 17500     0 20000 17500 20000 20000     0     0 \n",
      "  417   418   419   420   421   422   423   424   425   426   427   428   429 \n",
      "20000 17500 17500 20000 17500 20000 17500 20000 20000 17500 17500 20000 17500 \n",
      "  430   431   432   433   434   435   436   437   438   439   440   441   442 \n",
      "80000 20000 17500 17500 17500 20000     0 17500 35000 17500 87500 20000 80000 \n",
      "  443   444   445   446   447   448   449   450   451   452   453   454   455 \n",
      "    0 17500 20000     0 20000 87500 17500 17500 17500 20000 80000 35000 17500 \n",
      "  456   457   458   459   460   461   462   463   464   465   466   467   468 \n",
      "17500 17500 20000     0 35000 17500 87500 20000 87500 17500 87500 17500 20000 \n",
      "  469   470   471   472   473   474   475   476   477   478   479   480   481 \n",
      "17500 20000 87500 17500 20000 20000 20000 17500 20000 20000     0 87500     0 \n",
      "  482   483   484   485   486   487   488   489   490   491   492   493   494 \n",
      "    0     0     0     0     0 80000 17500     0     0     0 35000 17500 17500 \n",
      "  495   496   497   498   499   500   501   502   503   504   505   506   507 \n",
      "87500 35000 87500     0     0     0     0 17500     0     0     0     0     0 \n",
      "  508   509   510   511   512   513   514   515   516   517   518   519   520 \n",
      "    0 35000     0 20000     0 17500     0     0     0 87500     0 35000 17500 \n",
      "  521   522   523   524   525   526   527   528   529   530   531   532   533 \n",
      "    0     0     0     0     0     0 35000     0     0 87500 17500 20000     0 \n",
      "  534   535   536   537   538   539   540   541   542   543   544   545   546 \n",
      "20000 87500 20000 20000 17500     0 17500 20000 17500     0     0     0     0 \n",
      "  547   548   549   550   551   552   553   554   555   556   557   558   559 \n",
      "    0     0 17500     0 20000 20000     0 20000 17500     0     0     0 17500 \n",
      "  560   561   562   563   564   565   566   567   568   569   570   571   572 \n",
      "17500 17500     0     0 17500     0 17500     0     0 35000 20000 20000 17500 \n",
      "  573   574   575   576   577   578   579   580   581   582   583   584   585 \n",
      "17500     0 87500     0 35000     0 17500     0     0     0 17500     0     0 \n",
      "  586   587   588   589   590   591   592   593   594   595   596   597   598 \n",
      "17500     0     0 17500     0 17500     0 17500     0     0     0 87500     0 \n",
      "  599   600   601   602   603   604   605   606   607   608   609   610   611 \n",
      "17500     0 20000 87500 17500 17500 17500 20000 35000 17500 17500 80000     0 \n",
      "  612   613   614   615   616   617   618   619   620   621   622   623   624 \n",
      "17500 20000     0 20000     0 87500     0 17500     0     0 80000     0 17500 \n",
      "  625   626   627   628   629   630   631   632   633   634   635   636   637 \n",
      "87500     0 35000 17500 17500 17500 17500     0     0 17500     0 17500 20000 \n",
      "  638   639   640   641   642   643   644   645   646   647   648   649   650 \n",
      "35000     0     0     0 87500 87500 17500 17500     0 87500     0 80000     0 \n",
      "  651   652   653   654   655   656   657   658   659   660   661   662   663 \n",
      "17500 17500 35000 17500 87500 17500 17500 20000 20000     0 80000     0 35000 \n",
      "  664   665   666   667   668   669   670   671   672   673   674   675   676 \n",
      "17500 17500 80000 20000 20000 20000 17500 20000 87500 87500 87500 20000 87500 \n",
      "  677   678   679   680   681   682   683   684   685   686   687   688   689 \n",
      "    0 20000 17500 80000     0 35000     0     0 87500 35000     0 17500 17500 \n",
      "  690   691   692   693   694   695   696   697   698   699   700   701   702 \n",
      "17500     0 17500 20000     0 80000 17500 20000 20000 80000     0     0     0 \n",
      "  703   704   705   706   707   708   709   710   711   712   713   714   715 \n",
      "20000 17500     0 17500 20000 17500 20000     0     0 20000     0 17500     0 \n",
      "  716   717   718   719   720   721   722   723   724   725   726   727   728 \n",
      "    0 17500     0 35000     0 17500     0 17500 17500     0 17500     0 17500 \n",
      "  729   730   731   732   733   734   735   736   737   738   739   740   741 \n",
      "    0 17500 20000 87500 35000 17500 20000 17500 17500 17500     0 17500     0 \n",
      "  742   743   744   745   746   747   748   749   750   751   752   753   754 \n",
      "    0 17500     0     0     0     0 35000 20000     0 20000 80000     0 20000 \n",
      "  755   756   757   758   759   760   761   762   763   764   765   766   767 \n",
      "    0 35000 20000 17500 17500 17500 80000     0 17500     0 87500     0 80000 \n",
      "  768   769   770   771   772   773   774   775   776   777   778   779   780 \n",
      "17500     0     0     0 17500     0 17500 20000 87500     0 20000     0 17500 \n",
      "  781   782   783   784   785   786   787   788   789   790   791   792   793 \n",
      "    0     0 17500 17500 80000 20000 17500 17500 20000 17500     0 17500 87500 \n",
      "  794   795   796   797   798   799   800   801   802   803   804   805   806 \n",
      "17500 17500 20000 17500 17500 17500 17500 20000 17500 20000     0 17500 17500 \n",
      "  807   808   809   810   811   812   813   814   815   816   817   818   819 \n",
      "80000 20000     0 17500 17500 17500 17500     0     0 80000     0     0 20000 \n",
      "  820   821   822   823   824   825   826   827   828   829   830   831   832 \n",
      "17500 35000 35000 20000 20000 17500 87500 35000     0 17500     0     0 17500 \n",
      "  833   834   835   836   837   838   839   840   841   842   843   844   845 \n",
      "20000 20000 17500 17500 20000 80000 20000 87500     0 20000 35000 17500 17500 \n",
      "  846   847   848   849   850   851   852   853   854   855   856   857   858 \n",
      "17500     0 20000 35000 87500     0 87500     0 17500 17500     0 17500     0 \n",
      "  859   860   861   862   863   864   865   866   867   868   869   870   871 \n",
      "20000     0 17500     0 17500     0 20000 20000 17500     0 20000 17500 17500 \n",
      "  872   873   874   875   876   877   878   879   880   881   882   883   884 \n",
      "20000     0     0 20000     0     0     0     0     0 17500     0     0     0 \n",
      "  885   886   887   888   889   890   891   892   893   894   895   896   897 \n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0 \n",
      "  898   899   900   901   902   903   904   905   906   907   908   909   910 \n",
      "17500     0     0 17500 17500     0     0 20000     0     0 17500     0     0 \n",
      "  911   912   913   914   915   916   917   918   919   920   921   922   923 \n",
      "17500 17500 17500 20000 17500 35000 35000 20000 87500 20000     0 17500 17500 \n",
      "  924   925   926   927   928   929   930   931   932   933   934   935   936 \n",
      "    0 17500 17500     0     0 17500     0 17500 20000 20000 17500 17500 17500 \n",
      "  937   938   939   940   941   942   943   944   945   946   947   948   949 \n",
      "17500     0     0     0     0 17500     0 17500 17500     0 17500 80000 80000 \n",
      "  950   951   952   953   954   955   956   957   958   959   960   961   962 \n",
      "17500     0 17500     0 17500     0 17500 17500     0 17500 17500 17500 20000 \n",
      "  963   964   965   966   967   968   969   970   971   972   973   974   975 \n",
      "    0     0     0     0     0     0 17500     0     0     0     0     0 17500 \n",
      "  976   977   978   979   980   981   982   983   984   985   986   987   988 \n",
      "20000 17500 20000 17500 17500 17500 17500 17500 17500 17500 80000 80000 17500 \n",
      "  989   990   991   992   993   994   995   996   997   998   999  1000 \n",
      "17500 80000 17500     0 17500 17500     0     0     0 17500 17500 17500 \n",
      "12 Levels: 0 17500 20000 22400 26600 35000 53200 80000 87500 169600 ... 1312500\n"
     ]
    }
   ],
   "source": [
    "apprentissage <- read.table(\"apprentissage.csv\", sep = \",\" ,header = FALSE)\n",
    "test <- read.table(\"test.csv\", sep = \",\" ,header = FALSE)\n",
    "loopGetModel(apprentissage, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
