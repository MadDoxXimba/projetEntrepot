{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#Objectifs:\n",
    "#  Programmer sous R:\n",
    "#    1) Une fonction pour la (TRAIN-TEST) validation répétée\n",
    "#    2) Une fonction pour la validation croisée (K feuilles)\n",
    "#    3) Une fonction pour la validation croisée imbriquée\n",
    "#    4) Une fonction pour le Leave One Out (avec k = n)\n",
    "# \n",
    "# deux critères à valider: moyenne des performances et écart-type des \n",
    "\n",
    "# construction de modèles (ou librairies de notre choix):\n",
    "# library(rpart) = algos de décisions -> CART: classification and regression tree (classif ou regression)\n",
    "# library(MASS) = algo de décisions -> LDA : linear decision analysis: (classif binaire)\n",
    "# library(FNN) : K plus proche voisin (k-PPV)\n",
    "# tree <- rpart(X10 ~ ., data= mesData, method= 'class')  ici ~ = en fonction de et . = toutes les autres variables\n",
    "# tree <- rpart(X10 ~ ., data= mesData, method= 'class', control=rpart.control(minsplit=50), cp= val entre 0 et 1)  ici ~ = en fonction de et . = toutes les autres variables\n",
    "# predict(tree, mesNouvellesDonnées, type='class')\n",
    "# predict(tree, mesNouvellesDonnées, type='prob')\n",
    "# JEUX de données madoc: Breiman: wave5000\n",
    "\n",
    "# attente livrable: les fonctions, mini rapport explication fonction et comparaison des modèles(1,2,3,4) :robustesse sur les données de Breiman\n",
    "\n",
    "# en sortie un vecteur mélanger de 1 à n: en entré un entier\n",
    "# fonction sample déjà défini\n",
    "\n",
    "\n",
    "# Question 1\n",
    "#data = dataframe avec une colonne réel\n",
    "#k = le nombre de répétition\n",
    "#predictColumn = string = nom de la colonne X10\n",
    "library(rpart)\n",
    "validationRepeteeRPART = function (data, k) {\n",
    "  errorRate = c();\n",
    "  for (i in 1:k) {\n",
    "    #on mélange les données\n",
    "    randomData = data[sample(nrow(data)),]\n",
    "    #les 20% premières lignes sont les données de tests\n",
    "    testData = randomData[1: 1000,]\n",
    "    #les 80% autres sont les données pour la construction de modèle\n",
    "    modalData = randomData[1000:nrow(data),]\n",
    "    #on calcule la précision (le taux d'erreurs)\n",
    "    tree = rpart(modalData$X10~.,modalData, method=\"class\")\n",
    "    prediction = predict(tree, testData, type=\"class\")\n",
    "    \n",
    "    #utiliser predict pour trouver le taux d'erreur entre data et predict puis utiliser table\n",
    "    contingencyTable = table(testData$X10, prediction)\n",
    "    \n",
    "    #dans une matrice de confusion, les individus en diagonale sont les biens classés donc pour avoir le taux d'erreur on calcule la somme de tous les autres cases/la somme totale de toutes les cases\n",
    "    sumError = 0\n",
    "    total = 0\n",
    "    for (i in 1:nrow(contingencyTable)) {\n",
    "      for (j in 1:ncol(contingencyTable)) {\n",
    "        if (i != j) {\n",
    "          sumError = sumError + contingencyTable[i,j]\n",
    "        }\n",
    "        total = total + contingencyTable[i,j]\n",
    "      }\n",
    "    }\n",
    "    errorRate = c(errorRate, c(sumError/total))\n",
    "  }\n",
    "  return(mean(errorRate))\n",
    "}\n",
    "\n",
    "library(MASS)\n",
    "\n",
    "validationRepeteeLDA = function (data, k) {\n",
    "  errorRate = c()\n",
    "  for (i in 1:k) {\n",
    "    #on mélange les données\n",
    "    randomData = data[sample(nrow(data)),]\n",
    "    #les 20% premières lignes sont les données de tests\n",
    "    testData = randomData[1: 1000,]\n",
    "    #les 80% autres sont les données pour la construction de modèle\n",
    "    modalData = randomData[1000:nrow(data),]\n",
    "    #on calcule la précision (le taux d'erreurs)\n",
    "    tree = lda(modalData$X10~.,modalData, method=\"moment\")\n",
    "    prediction = predict(tree, testData, type=\"moment\")\n",
    "    #utiliser predict pour trouver le taux d'erreur entre data et predict puis utiliser table\n",
    "    contingencyTable = table(testData$X10, prediction$class)\n",
    "    #dans une matrice de confusion, les individus en diagonale sont les biens classés donc pour avoir le taux d'erreur on calcule la somme de tous les autres cases/la somme totale de toutes les cases\n",
    "    sumError = 0\n",
    "    total = 0\n",
    "    for (i in 1:nrow(contingencyTable)) {\n",
    "      for (j in 1:ncol(contingencyTable)) {\n",
    "        if (i != j) {\n",
    "          sumError = sumError + contingencyTable[i,j]\n",
    "        }\n",
    "        total = total + contingencyTable[i,j]\n",
    "      }\n",
    "    }\n",
    "    errorRate = c(errorRate, c(sumError/total))\n",
    "  }\n",
    "  return(mean(errorRate))\n",
    "}\n",
    "\n",
    "#Exercice 2\n",
    "#data = dataframe\n",
    "#partitions = integer\n",
    "validationCroiseeRPART = function(data, partitions, metric) {\n",
    "  errorRate = c()\n",
    "  #on mélange les données\n",
    "  randomData = data[sample(nrow(data)),]\n",
    "  #list\n",
    "  setPartitions = split(randomData, 1:partitions)\n",
    "  for (i in 1:(partitions)) {\n",
    "    tempSetPartitions = setPartitions\n",
    "    currentTestData = setPartitions[[i]]\n",
    "    currentModalDataList = tempSetPartitions[-i]\n",
    "    #fusion dataframe\n",
    "    currentModalData = rbind.data.frame(currentModalDataList[[1]], currentModalDataList[[2]])\n",
    "    \n",
    "    for (j in 3:(partitions-1)) {\n",
    "      currentModalData = rbind.data.frame(currentModalData, currentModalDataList[[j]])\n",
    "    }\n",
    "    \n",
    "    numOfLinesTestCurrentModalData = as.integer(length(currentModalData)*0.2)\n",
    "    numOflinesModalCurrentModalData = as.integer(length(currentModalData)*0.8)\n",
    "    \n",
    "    testData_step2 = currentModalData[1:numOfLinesTestCurrentModalData,]\n",
    "    modalData_step2 = currentModalData[numOfLinesTestCurrentModalData+1:numOflinesModalCurrentModalData,]\n",
    "    \n",
    "    #on calcule la précision (le taux d'erreurs)\n",
    "    tree = rpart(modalData_step2$X10~.,modalData_step2, method=\"class\")\n",
    "    prediction = predict(tree, testData_step2, type=\"class\")\n",
    "    #utiliser predict pour trouver le taux d'erreur entre data et predict puis utiliser table\n",
    "    contingencyTable = table(testData_step2$X10, prediction)\n",
    "    \n",
    "    total = 0\n",
    "    sumError = 0\n",
    "    for (i in 1:nrow(contingencyTable)) {\n",
    "      for (j in 1:ncol(contingencyTable)) {\n",
    "        if (i != j) {\n",
    "          sumError = sumError + contingencyTable[i,j]\n",
    "        }\n",
    "        total = total + contingencyTable[i,j]\n",
    "      }\n",
    "    }\n",
    "    errorRate = c(errorRate, c(sumError/total))\n",
    "    \n",
    "  }\n",
    "  \n",
    "  meanPrecision = mean(errorRate)\n",
    "  robustesse_calculate = 0\n",
    "  \n",
    "  for (i in 1:length(errorRate)) {\n",
    "    robustesse_calculate = robustesse_calculate + (errorRate[i] - meanPrecision)*(errorRate[i] - meanPrecision)\n",
    "  }\n",
    "  #nombre de valeurs dans error rate est la même que le nombre de partitions\n",
    "  robustesse = robustesse_calculate/length(errorRate)\n",
    "  \n",
    "  if (metric == 1) {\n",
    "    return(robustesse)\n",
    "  } else {\n",
    "    return(mean(errorRate))\n",
    "  }\n",
    "  \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "validationCroiseeLDA = function(data, partitions, metric) {\n",
    "  errorRate = c()\n",
    "  #on mélange les données\n",
    "  randomData = data[sample(nrow(data)),]\n",
    "  #list\n",
    "  setPartitions = split(randomData, 1:partitions)\n",
    "  for (i in 1:(partitions)) {\n",
    "    tempSetPartitions = setPartitions\n",
    "    currentTestData = setPartitions[[i]]\n",
    "    currentModalDataList = tempSetPartitions[-i]\n",
    "    #fusion dataframe\n",
    "    currentModalData = rbind.data.frame(currentModalDataList[[1]], currentModalDataList[[2]])\n",
    "    \n",
    "    for (j in 3:(partitions-1)) {\n",
    "      currentModalData = rbind.data.frame(currentModalData, currentModalDataList[[j]])\n",
    "    }\n",
    "    \n",
    "    numOfLinesTestCurrentModalData = as.integer(length(currentModalData)*0.2)\n",
    "    numOflinesModalCurrentModalData = as.integer(length(currentModalData)*0.8)\n",
    "    \n",
    "    testData_step2 = currentModalData[1:numOfLinesTestCurrentModalData,]\n",
    "    modalData_step2 = currentModalData[numOfLinesTestCurrentModalData+1:numOflinesModalCurrentModalData,]\n",
    "    \n",
    "    #on calcule la précision (le taux d'erreurs)\n",
    "    tree = lda(X10~.,modalData_step2)\n",
    "    prediction = predict(tree, testData_step2, type=\"class\")\n",
    "    #utiliser predict pour trouver le taux d'erreur entre data et predict puis utiliser table\n",
    "    contingencyTable = table(testData_step2$X10, prediction$class)\n",
    "    \n",
    "    total = 0\n",
    "    sumError = 0\n",
    "    for (i in 1:nrow(contingencyTable)) {\n",
    "      for (j in 1:ncol(contingencyTable)) {\n",
    "        if (i != j) {\n",
    "          sumError = sumError + contingencyTable[i,j]\n",
    "        }\n",
    "        total = total + contingencyTable[i,j]\n",
    "      }\n",
    "    }\n",
    "    errorRate = c(errorRate, c(sumError/total))\n",
    "    \n",
    "  }\n",
    "  \n",
    "  meanPrecision = mean(errorRate)\n",
    "  robustesse_calculate = 0\n",
    "  \n",
    "  for (i in 1:length(errorRate)) {\n",
    "    robustesse_calculate = robustesse_calculate + (errorRate[i] - meanPrecision)*(errorRate[i] - meanPrecision)\n",
    "  }\n",
    "  #nombre de valeurs dans error rate est la même que le nombre de partitions\n",
    "  robustesse = robustesse_calculate/length(errorRate)\n",
    "  \n",
    "  if (metric == 1) {\n",
    "    return(robustesse)\n",
    "  } else {\n",
    "    return(mean(errorRate))\n",
    "  }\n",
    "  \n",
    "}\n",
    "\n",
    "\n",
    "#appel de fonction validationCroisee défini précédemment\n",
    "#en paramètre k = le nombre de répétition\n",
    "validationCroiseeRepetee = function (data, partitions, k) {\n",
    "  robustesseMean = 0\n",
    "  errorRateMean = 0\n",
    "  \n",
    "  for (i in 1:k) {\n",
    "    robustesseMean = robustesseMean + validationCroiseeRPART(data, partitions, 1)\n",
    "    errorRateMean = errorRateMean + validationCroiseeRPART(data, partitions, 0)\n",
    "  }\n",
    "  \n",
    "  robustesseMean = robustesseMean/k\n",
    "  errorRateMean = errorRateMean/k\n",
    "  \n",
    "  return(c(robustesseMean, errorRateMean))\n",
    "  \n",
    "}\n",
    "\n",
    "#data = dataframe\n",
    "#partitions = nombre de partition où on va split le dataset\n",
    "validationCroiseeImpliquee = function(data, partitions) {\n",
    "  \n",
    "  errorRate = c()\n",
    "  #on mélange les données\n",
    "  randomData = data[sample(nrow(data)),]\n",
    "  #list\n",
    "  setPartitions = split(randomData, 1:partitions)\n",
    "  listErrorRate = c()\n",
    "  \n",
    "  for (i in 1:partitions) {\n",
    "    \n",
    "    errorRate = c()\n",
    "    \n",
    "    for (i in 1:partitions-1) {\n",
    " \n",
    "      tempSetPartitions = setPartitions\n",
    "      currentTestData = setPartitions[[i]]\n",
    "      currentModalDataList = tempSetPartitions[-i]\n",
    "      #fusion dataframe\n",
    "      currentModalData = rbind.data.frame(currentModalDataList[[1]], currentModalDataList[[2]])\n",
    "      \n",
    "      for (j in 3:(partitions-2)) {\n",
    "        currentModalData = rbind.data.frame(currentModalData, currentModalDataList[[j]])\n",
    "      }\n",
    "      \n",
    "      numOfLinesTestCurrentModalData = as.integer(length(currentModalData)*0.2)\n",
    "      numOflinesModalCurrentModalData = as.integer(length(currentModalData)*0.8)\n",
    "      \n",
    "      testData_step2 = currentModalData[1:numOfLinesTestCurrentModalData,]\n",
    "      modalData_step2 = currentModalData[numOfLinesTestCurrentModalData+1:numOflinesModalCurrentModalData,]\n",
    "      \n",
    "      #on calcule la précision (le taux d'erreurs)\n",
    "      tree = lda(X10~.,modalData_step2)\n",
    "      prediction = predict(tree, testData_step2, type=\"class\")\n",
    "      #utiliser predict pour trouver le taux d'erreur entre data et predict puis utiliser table\n",
    "      contingencyTable = table(testData_step2$X10, prediction$class)\n",
    "      \n",
    "      total = 0\n",
    "      sumError = 0\n",
    "      for (i in 1:nrow(contingencyTable)) {\n",
    "        for (j in 1:ncol(contingencyTable)) {\n",
    "          if (i != j) {\n",
    "            sumError = sumError + contingencyTable[i,j]\n",
    "          }\n",
    "          total = total + contingencyTable[i,j]\n",
    "        }\n",
    "      }\n",
    "      errorRate = c(errorRate, c(sumError/total))\n",
    "    }\n",
    "    \n",
    "    listErrorRate = c(c(listErrorRate), mean(errorRate))\n",
    "    \n",
    "  }\n",
    "  \n",
    "  return(listErrorRate)\n",
    "  \n",
    "}\n",
    "\n",
    "#appel de la fonction validationCroisee\n",
    "#en paramètre data: un dataframe\n",
    "leaveOneOut = function(data) {\n",
    "  numberOfrows = nrow(data)\n",
    "  return(c(validationCroiseeRPART(data, numberOfrows, 0), validationCroiseeRPART(data, numberOfrows, 1)))\n",
    "}\n",
    "\n",
    "\n",
    "#appel de tous les fonctions définies précédemment\n",
    "\n",
    "algorithmSelection = function(data, K) {\n",
    "  \n",
    "  validationCroiseeRPARTErrorRate = validationRepeteeLDA(data, K)\n",
    "  validationCroiseeLDAErrorRate = validationRepeteeRPART(data, K)\n",
    "  \n",
    "  if (validationCroiseeRPARTErrorRate > validationCroiseeLDAErrorRate) {\n",
    "    return(\"SOLUTION: LDA\")\n",
    "  } else {\n",
    "    return(\"SOLUTION: RPART\")\n",
    "  }\n",
    "  \n",
    "  return(\"ERROR\")\n",
    "}\n",
    "\n",
    "validationCroiseeGetModel = function(data, partitions, colonneCible, errorRateThreshold = 0.3) {\n",
    "  errorRate = c()\n",
    "  #on m\\u{fffd}lange les donn\\u{fffd}es\n",
    "  randomData = data[sample(nrow(data)),]\n",
    "  #list\n",
    "  setPartitions = split(randomData, 1:partitions)\n",
    "  for (i in 1:(partitions)) {\n",
    "    tempSetPartitions = setPartitions\n",
    "    currentTestData = setPartitions[[i]]\n",
    "    currentModalDataList = tempSetPartitions[-i]\n",
    "    #fusion dataframe\n",
    "    currentModalData = rbind.data.frame(currentModalDataList[[1]], currentModalDataList[[2]])\n",
    "    \n",
    "    for (j in 3:(partitions-1)) {\n",
    "      currentModalData = rbind.data.frame(currentModalData, currentModalDataList[[j]])\n",
    "    }\n",
    "    \n",
    "    numOfLinesTestCurrentModalData = as.integer(length(currentModalData)*0.2)\n",
    "    numOflinesModalCurrentModalData = as.integer(length(currentModalData)*0.8)\n",
    "    \n",
    "    testData_step2 = currentModalData[1:numOfLinesTestCurrentModalData,]\n",
    "    modalData_step2 = currentModalData[numOfLinesTestCurrentModalData+1:numOflinesModalCurrentModalData,]\n",
    "    \n",
    "    #on calcule la pr\\u{fffd}cision (le taux d'erreurs)\n",
    "    #formulaString = paste(\"modalData_step2$\", colonneCible, \"~.\",sep=\"\")\n",
    "    #formulaCible= as.formula(formulaString)\n",
    "    #tree = rpart(formulaCible, modalData_step2, method=\"class\", control=rpart.control(minsplit=5,cp=0))\n",
    "      \n",
    "    tree = rpart(modalData_step2$X1~., modalData_step2, method=\"class\", control=rpart.control(minsplit=5,cp=0))\n",
    "    prediction = predict(tree, testData_step2, type=\"class\")\n",
    "      \n",
    "    #utiliser predict pour trouver le taux d'erreur entre data et predict puis utiliser table\n",
    "    #formulaString = paste(\"testData_step2\", colonneCible,sep=\"$\")\n",
    "    #formulaCible2 = as.formula(formulaString)\n",
    "      \n",
    "    contingencyTable = table(testData_step2$X1, prediction)\n",
    "    \n",
    "    total = 0\n",
    "    sumError = 0\n",
    "    for (i in 1:nrow(contingencyTable)) {\n",
    "      for (j in 1:ncol(contingencyTable)) {\n",
    "        if (i != j) {\n",
    "          sumError = sumError + contingencyTable[i,j]\n",
    "        }\n",
    "        total = total + contingencyTable[i,j]\n",
    "      }\n",
    "    }\n",
    "    errorRate = c(errorRate, c(sumError/total))\n",
    "    \n",
    "  }\n",
    "  \n",
    "  meanPrecision = mean(errorRate)\n",
    "  robustesse_calculate = 0\n",
    "  \n",
    "  for (i in 1:length(errorRate)) {\n",
    "    robustesse_calculate = robustesse_calculate + (errorRate[i] - meanPrecision)*(errorRate[i] - meanPrecision)\n",
    "  }\n",
    "  #nombre de valeurs dans error rate est la m\\u{fffd}me que le nombre de partitions\n",
    "  robustesse = robustesse_calculate/length(errorRate)\n",
    "  \n",
    "  if (mean(errorRate) <= errorRateThreshold) {\n",
    "    listResult = list(mean(errorRate), tree)\n",
    "    print(\"Error Rate < 0.3\")\n",
    "    print(mean(errorRate))\n",
    "    return(listResult)\n",
    "  }else{\n",
    "    listResult = list(0, tree)\n",
    "    print(\"Error Rate > 0.3, WRONG MODEL\")\n",
    "    print(mean(errorRate))\n",
    "    return(listResult)\n",
    "  }\n",
    "}\n",
    "\n",
    "#Variable cible : PREDICTION CHIFFRE D'AFFAIRES\n",
    "GetModelChiffreAffaires = function(data, partitions){\n",
    "  result = 0\n",
    "  while(result == 0){\n",
    "    print(\"generating new model ...\")\n",
    "    donneesAppr = data[ , -c(1,2,3,4,5,6,7,8,9)]\n",
    "    names(donneesAppr) = c(\"X1\",\"X2\",\"X3\",\"X4\",\"X5\",\"X6\",\"X7\",\"X8\",\"X9\",\"X10\",\"X11\",\"X12\",\"X13\",\"X14\",\"X15\",\"X16\",\"X17\",\"X18\",\"X19\",\"X20\",\"X21\",\"X22\",\"X23\",\"X24\",\"X25\",\"X26\",\"X27\",\"X28\",\"X29\",\"X30\",\"X31\")\n",
    "    listResult = validationCroiseeGetModel(donneesAppr, partitions, \"X1\")\n",
    "    result = listResult[[1]]\n",
    "  }\n",
    "  print(listResult)\n",
    "  donneesTest = test[ , -c(1,2,3,36,37,38,39)]\n",
    "  names(donneesTest) = c(\"X2\",\"X3\",\"X4\",\"X5\",\"X6\",\"X7\",\"X8\",\"X9\",\"X10\",\"X11\",\"X12\",\"X13\",\"X14\",\"X15\",\"X16\",\"X17\",\"X18\",\"X19\",\"X20\",\"X21\",\"X22\",\"X23\",\"X24\",\"X25\",\"X26\",\"X27\",\"X28\",\"X29\",\"X30\",\"X31\")\n",
    "  predictionChiffreAffaire = predict(listResult[[2]], donneesTest, type=\"class\")\n",
    "  print(predictionChiffreAffaire)\n",
    "  return (predictionChiffreAffaire)\n",
    "}\n",
    "\n",
    "#Variable cible : CAPACITE D'EMPRUNT\n",
    "GetModelCapaciteEmprunt = function(data, partitions){\n",
    "  result = 0\n",
    "  while(result == 0){\n",
    "    print(\"generating new model ...\")\n",
    "    donneesAppr = data[ , -c(1,2,3,4,5,6,7,8,10)]\n",
    "    names(donneesAppr) = c(\"X1\",\"X2\",\"X3\",\"X4\",\"X5\",\"X6\",\"X7\",\"X8\",\"X9\",\"X10\",\"X11\",\"X12\",\"X13\",\"X14\",\"X15\",\"X16\",\"X17\",\"X18\",\"X19\",\"X20\",\"X21\",\"X22\",\"X23\",\"X24\",\"X25\",\"X26\",\"X27\",\"X28\",\"X29\",\"X30\",\"X31\")\n",
    "    listResult = validationCroiseeGetModel(donneesAppr, partitions, \"X1\", 0.6)\n",
    "    result = listResult[[1]]\n",
    "  }\n",
    "  print(listResult)\n",
    "  donneesTest = test[ , -c(1,2,3,36,37,38,39)]\n",
    "  names(donneesTest) = c(\"X2\",\"X3\",\"X4\",\"X5\",\"X6\",\"X7\",\"X8\",\"X9\",\"X10\",\"X11\",\"X12\",\"X13\",\"X14\",\"X15\",\"X16\",\"X17\",\"X18\",\"X19\",\"X20\",\"X21\",\"X22\",\"X23\",\"X24\",\"X25\",\"X26\",\"X27\",\"X28\",\"X29\",\"X30\",\"X31\")\n",
    "  predictionCapaciteEmprunt = predict(listResult[[2]], donneesTest, type=\"class\")\n",
    "  print(predictionCapaciteEmprunt)\n",
    "  return (predictionCapaciteEmprunt)\n",
    "}\n",
    "\n",
    "GetModelSecteurOne = function(data, partitions){\n",
    "#Variable cible : SECTEUR 1\n",
    "  result = 0\n",
    "  while(result == 0){\n",
    "    print(\"generating new model ...\")\n",
    "    donneesAppr = data[ , -c(1,3,4,5,6,7,8,9,10)]\n",
    "    names(donneesAppr) = c(\"X1\",\"X2\",\"X3\",\"X4\",\"X5\",\"X6\",\"X7\",\"X8\",\"X9\",\"X10\",\"X11\",\"X12\",\"X13\",\"X14\",\"X15\",\"X16\",\"X17\",\"X18\",\"X19\",\"X20\",\"X21\",\"X22\",\"X23\",\"X24\",\"X25\",\"X26\",\"X27\",\"X28\",\"X29\",\"X30\",\"X31\")\n",
    "    donneesAppr\n",
    "    listResult = validationCroiseeGetModel(donneesAppr, partitions, \"X1\")\n",
    "    result = listResult[[1]]\n",
    "  }\n",
    "  print(listResult)\n",
    "  donneesTest = test[ , -c(1,2,3,36,37,38,39)]\n",
    "  donneesTest\n",
    "  names(donneesTest) = c(\"X2\",\"X3\",\"X4\",\"X5\",\"X6\",\"X7\",\"X8\",\"X9\",\"X10\",\"X11\",\"X12\",\"X13\",\"X14\",\"X15\",\"X16\",\"X17\",\"X18\",\"X19\",\"X20\",\"X21\",\"X22\",\"X23\",\"X24\",\"X25\",\"X26\",\"X27\",\"X28\",\"X29\",\"X30\",\"X31\")\n",
    "  predictionSecteurOne = predict(listResult[[2]], donneesTest, type=\"class\")\n",
    "  print(predictionSecteurOne)\n",
    "  return (predictionSecteurOne)\n",
    "}\n",
    "\n",
    "GetModelSecteurTwo = function(data, partitions){\n",
    "#Variable cible : SECTEUR 2\n",
    "  result = 0\n",
    "  while(result == 0){\n",
    "    print(\"generating new model ...\")\n",
    "    donneesAppr = data[ , -c(1,2,4,5,6,7,8,9,10)]\n",
    "    names(donneesAppr) = c(\"X1\",\"X2\",\"X3\",\"X4\",\"X5\",\"X6\",\"X7\",\"X8\",\"X9\",\"X10\",\"X11\",\"X12\",\"X13\",\"X14\",\"X15\",\"X16\",\"X17\",\"X18\",\"X19\",\"X20\",\"X21\",\"X22\",\"X23\",\"X24\",\"X25\",\"X26\",\"X27\",\"X28\",\"X29\",\"X30\",\"X31\")\n",
    "    donneesAppr\n",
    "    listResult = validationCroiseeGetModel(donneesAppr, partitions, \"X1\")\n",
    "    result = listResult[[1]]\n",
    "  }\n",
    "  print(listResult)\n",
    "  donneesTest = test[ , -c(1,2,3,36,37,38,39)]\n",
    "  donneesTest\n",
    "  names(donneesTest) = c(\"X2\",\"X3\",\"X4\",\"X5\",\"X6\",\"X7\",\"X8\",\"X9\",\"X10\",\"X11\",\"X12\",\"X13\",\"X14\",\"X15\",\"X16\",\"X17\",\"X18\",\"X19\",\"X20\",\"X21\",\"X22\",\"X23\",\"X24\",\"X25\",\"X26\",\"X27\",\"X28\",\"X29\",\"X30\",\"X31\")\n",
    "  predictionSecteurTwo = predict(listResult[[2]], donneesTest, type=\"class\")\n",
    "  print(predictionSecteurTwo)\n",
    "  return (predictionSecteurTwo)\n",
    "}\n",
    "\n",
    "GetModelSecteurParticulier = function(data, partitions){\n",
    "#Variable cible : SECTEUR PARTICULIER\n",
    "  result = 0\n",
    "  while(result == 0){\n",
    "    print(\"generating new model ...\")\n",
    "    donneesAppr = data[ , -c(1,2,3,5,6,7,8,9,10)]\n",
    "    names(donneesAppr) = c(\"X1\",\"X2\",\"X3\",\"X4\",\"X5\",\"X6\",\"X7\",\"X8\",\"X9\",\"X10\",\"X11\",\"X12\",\"X13\",\"X14\",\"X15\",\"X16\",\"X17\",\"X18\",\"X19\",\"X20\",\"X21\",\"X22\",\"X23\",\"X24\",\"X25\",\"X26\",\"X27\",\"X28\",\"X29\",\"X30\",\"X31\")\n",
    "    donneesAppr\n",
    "    listResult = validationCroiseeGetModel(donneesAppr, partitions, \"X1\")\n",
    "    result = listResult[[1]]\n",
    "  }\n",
    "  print(listResult)\n",
    "  donneesTest = test[ , -c(1,2,3,36,37,38,39)]\n",
    "  donneesTest\n",
    "  names(donneesTest) = c(\"X2\",\"X3\",\"X4\",\"X5\",\"X6\",\"X7\",\"X8\",\"X9\",\"X10\",\"X11\",\"X12\",\"X13\",\"X14\",\"X15\",\"X16\",\"X17\",\"X18\",\"X19\",\"X20\",\"X21\",\"X22\",\"X23\",\"X24\",\"X25\",\"X26\",\"X27\",\"X28\",\"X29\",\"X30\",\"X31\")\n",
    "  predictionSecteurParticulier = predict(listResult[[2]], donneesTest, type=\"class\")\n",
    "  print(predictionSecteurParticulier)\n",
    "  return (predictionSecteurParticulier)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"generating new model ...\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in split.default(x = seq_len(nrow(x)), f = f, drop = drop, ...):\n",
      "\"la taille de données n'est pas un multiple de la variable découpée\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Error Rate > 0.3, WRONG MODEL\"\n",
      "[1] 0.8333333\n",
      "[1] \"generating new model ...\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in split.default(x = seq_len(nrow(x)), f = f, drop = drop, ...):\n",
      "\"la taille de données n'est pas un multiple de la variable découpée\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Error Rate > 0.3, WRONG MODEL\"\n",
      "[1] 0.65\n",
      "[1] \"generating new model ...\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in split.default(x = seq_len(nrow(x)), f = f, drop = drop, ...):\n",
      "\"la taille de données n'est pas un multiple de la variable découpée\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Error Rate < 0.3\"\n",
      "[1] 0.2166667\n",
      "[[1]]\n",
      "[1] 0.2166667\n",
      "\n",
      "[[2]]\n",
      "n= 25 \n",
      "\n",
      "node), split, n, loss, yval, (yprob)\n",
      "      * denotes terminal node\n",
      "\n",
      " 1) root 25 16 0 (0.36 0.08 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04)  \n",
      "   2) X2< 0.5 9  0 0 (1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0) *\n",
      "   3) X2>=0.5 16 14 17500 (0 0.12 0.062 0.062 0.062 0.062 0.062 0.062 0.062 0.062 0.062 0.062 0.062 0.062 0.062 0.062)  \n",
      "     6) X2< 1.5 5  3 17500 (0 0.4 0.2 0.2 0.2 0 0 0 0 0 0 0 0 0 0 0)  \n",
      "      12) X28< 1.02 2  0 17500 (0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0) *\n",
      "      13) X28>=1.02 3  2 20000 (0 0 0.33 0.33 0.33 0 0 0 0 0 0 0 0 0 0 0) *\n",
      "     7) X2>=1.5 11 10 35000 (0 0 0 0 0 0.091 0.091 0.091 0.091 0.091 0.091 0.091 0.091 0.091 0.091 0.091)  \n",
      "      14) X2< 5 4  3 35000 (0 0 0 0 0 0.25 0.25 0.25 0.25 0 0 0 0 0 0 0) *\n",
      "      15) X2>=5 7  6 105000 (0 0 0 0 0 0 0 0 0 0.14 0.14 0.14 0.14 0.14 0.14 0.14)  \n",
      "        30) X2< 8.5 3  2 105000 (0 0 0 0 0 0 0 0 0 0.33 0.33 0.33 0 0 0 0) *\n",
      "        31) X2>=8.5 4  3 192500 (0 0 0 0 0 0 0 0 0 0 0 0 0.25 0.25 0.25 0.25) *\n",
      "\n",
      "     1      2      3      4      5      6      7      8      9     10     11 \n",
      "     0  20000  35000  17500      0  35000  35000      0  20000  17500  35000 \n",
      "    12     13     14     15     16     17     18     19     20     21     22 \n",
      " 17500 105000  35000  17500      0  35000  35000 192500  20000 192500  20000 \n",
      "    23     24     25     26     27     28     29     30     31     32     33 \n",
      " 20000      0      0      0 192500      0  35000  35000  35000  35000 105000 \n",
      "    34     35     36     37     38     39     40     41     42     43     44 \n",
      " 17500  17500  20000  17500  20000 192500 105000  20000 105000 192500 192500 \n",
      "    45     46     47     48     49     50     51     52     53     54     55 \n",
      " 35000  35000 192500  17500 192500 192500 192500  20000  17500  35000 192500 \n",
      "    56     57     58     59     60     61     62     63     64     65     66 \n",
      " 17500 192500      0 105000 192500  20000      0      0 192500 105000      0 \n",
      "    67     68     69     70     71     72     73     74     75     76     77 \n",
      " 20000 192500  35000  35000  17500 192500      0 105000      0      0      0 \n",
      "    78     79     80     81     82     83     84     85     86     87     88 \n",
      "     0      0      0      0      0      0      0      0      0      0  17500 \n",
      "    89     90     91     92     93     94     95     96     97     98     99 \n",
      "     0 192500 105000 192500      0 105000 105000 192500  35000  17500  35000 \n",
      "   100    101    102    103    104    105    106    107    108    109    110 \n",
      "     0 105000 192500 192500 192500  17500      0      0  35000  35000  35000 \n",
      "   111    112    113    114    115    116    117    118    119    120    121 \n",
      " 17500  20000      0  20000      0 105000  35000  17500      0      0  35000 \n",
      "   122    123    124    125    126    127    128    129    130    131    132 \n",
      " 35000      0  35000      0      0  20000  35000 192500 192500 105000  20000 \n",
      "   133    134    135    136    137    138    139    140    141    142    143 \n",
      " 17500  35000  20000 105000  17500  20000 105000 192500 192500  35000      0 \n",
      "   144    145    146    147    148    149    150    151    152    153    154 \n",
      "     0 192500 192500 192500  17500  35000  17500 192500 192500  17500 105000 \n",
      "   155    156    157    158    159    160    161    162    163    164    165 \n",
      "     0  35000 192500 105000 192500  17500  17500      0  20000 105000      0 \n",
      "   166    167    168    169    170    171    172    173    174    175    176 \n",
      "     0      0      0      0 192500  35000      0      0      0      0      0 \n",
      "   177    178    179    180    181    182    183    184    185    186    187 \n",
      " 20000      0      0      0      0 192500      0  35000      0 105000  17500 \n",
      "   188    189    190    191    192    193    194    195    196    197    198 \n",
      " 35000 192500  17500 105000 192500  35000  35000  35000      0  35000      0 \n",
      "   199    200    201    202    203    204    205    206    207    208    209 \n",
      "192500  17500  35000      0      0  35000  20000  35000  20000  17500      0 \n",
      "   210    211    212    213    214    215    216    217    218    219    220 \n",
      "     0      0      0      0 192500  35000  17500      0  35000      0 192500 \n",
      "   221    222    223    224    225    226    227    228    229    230    231 \n",
      "105000 105000  17500  35000      0  17500  35000  17500      0  35000  20000 \n",
      "   232    233    234    235    236    237    238    239    240    241    242 \n",
      " 35000  17500  35000  20000  17500  20000      0      0      0  17500  17500 \n",
      "   243    244    245    246    247    248    249    250    251    252    253 \n",
      "105000      0      0      0      0      0  35000  20000      0      0      0 \n",
      "   254    255    256    257    258    259    260    261    262    263    264 \n",
      "     0 192500 192500 192500      0 105000  35000  35000  35000      0 192500 \n",
      "   265    266    267    268    269    270    271    272    273    274    275 \n",
      " 35000      0      0  17500 192500  35000 192500 192500  35000      0      0 \n",
      "   276    277    278    279    280    281    282    283    284    285    286 \n",
      "     0      0  17500      0      0      0      0  35000  17500 105000  17500 \n",
      "   287    288    289    290    291    292    293    294    295    296    297 \n",
      "     0      0  20000 192500 105000  20000  20000      0  35000      0  35000 \n",
      "   298    299    300    301    302    303    304    305    306    307    308 \n",
      "     0  35000      0 192500  35000  35000 105000      0  35000      0  17500 \n",
      "   309    310    311    312    313    314    315    316    317    318    319 \n",
      "     0  35000      0 105000      0 192500      0      0      0  35000 105000 \n",
      "   320    321    322    323    324    325    326    327    328    329    330 \n",
      "     0      0      0 105000 192500      0  17500  35000  35000 192500 105000 \n",
      "   331    332    333    334    335    336    337    338    339    340    341 \n",
      "     0 105000      0  20000 105000      0      0  20000 192500 192500 192500 \n",
      "   342    343    344    345    346    347    348    349    350    351    352 \n",
      "     0  35000 192500  35000 192500 192500  17500 192500 192500  35000  17500 \n",
      "   353    354    355    356    357    358    359    360    361    362    363 \n",
      "     0  17500  35000  17500 105000      0 105000 192500  35000  17500  17500 \n",
      "   364    365    366    367    368    369    370    371    372    373    374 \n",
      "192500 105000  35000 105000      0  17500  35000      0      0 192500      0 \n",
      "   375    376    377    378    379    380    381    382    383    384    385 \n",
      "105000  17500  20000      0      0  17500  17500  35000 105000  17500 105000 \n",
      "   386    387    388    389    390    391    392    393    394    395    396 \n",
      "192500      0      0      0      0      0      0      0      0      0      0 \n",
      "   397    398    399    400    401    402    403    404    405    406    407 \n",
      "     0      0 192500 105000  35000  17500      0  17500 105000  17500  35000 \n",
      "   408    409    410    411    412    413    414    415    416    417    418 \n",
      " 17500  17500      0  20000 105000  17500  20000      0      0  20000  20000 \n",
      "   419    420    421    422    423    424    425    426    427    428    429 \n",
      " 17500  17500  20000  20000  17500  35000  20000  20000  17500  17500  17500 \n",
      "   430    431    432    433    434    435    436    437    438    439    440 \n",
      " 35000  35000  17500  35000  17500  17500      0  20000  35000  35000 192500 \n",
      "   441    442    443    444    445    446    447    448    449    450    451 \n",
      " 20000  35000      0  20000  35000      0  17500 105000  35000  35000  20000 \n",
      "   452    453    454    455    456    457    458    459    460    461    462 \n",
      " 20000  35000 192500  20000  35000  17500  17500      0  35000  20000 192500 \n",
      "   463    464    465    466    467    468    469    470    471    472    473 \n",
      " 35000 192500  20000 105000  17500  20000  35000  20000 105000  17500  20000 \n",
      "   474    475    476    477    478    479    480    481    482    483    484 \n",
      " 20000  20000  20000  17500  17500      0 105000      0      0      0      0 \n",
      "   485    486    487    488    489    490    491    492    493    494    495 \n",
      "     0      0  35000  20000      0      0      0  20000 105000  17500 192500 \n",
      "   496    497    498    499    500    501    502    503    504    505    506 \n",
      "105000 192500      0      0      0      0 192500      0      0      0      0 \n",
      "   507    508    509    510    511    512    513    514    515    516    517 \n",
      "     0      0  17500      0  17500      0  17500      0      0      0 105000 \n",
      "   518    519    520    521    522    523    524    525    526    527    528 \n",
      "     0 192500  20000      0      0      0      0      0      0 192500      0 \n",
      "   529    530    531    532    533    534    535    536    537    538    539 \n",
      "     0 192500  35000  20000      0  35000 192500  20000  20000  20000      0 \n",
      "   540    541    542    543    544    545    546    547    548    549    550 \n",
      " 20000  35000  35000      0      0      0      0      0      0  20000      0 \n",
      "   551    552    553    554    555    556    557    558    559    560    561 \n",
      " 20000  35000      0  20000  20000      0      0      0  17500  20000  17500 \n",
      "   562    563    564    565    566    567    568    569    570    571    572 \n",
      "     0      0  17500      0  20000      0      0  20000  17500  17500  17500 \n",
      "   573    574    575    576    577    578    579    580    581    582    583 \n",
      " 20000      0 105000      0  35000      0 192500      0      0      0  35000 \n",
      "   584    585    586    587    588    589    590    591    592    593    594 \n",
      "     0      0  17500      0      0  20000      0  20000      0  20000      0 \n",
      "   595    596    597    598    599    600    601    602    603    604    605 \n",
      "     0      0 192500      0  17500      0  17500 105000  17500  17500 192500 \n",
      "   606    607    608    609    610    611    612    613    614    615    616 \n",
      " 20000  20000 192500  20000  35000      0  20000  35000      0  35000      0 \n",
      "   617    618    619    620    621    622    623    624    625    626    627 \n",
      "192500      0  35000      0      0  35000      0  17500 192500      0  35000 \n",
      "   628    629    630    631    632    633    634    635    636    637    638 \n",
      " 20000  17500  20000  35000      0      0  17500      0 192500  35000 192500 \n",
      "   639    640    641    642    643    644    645    646    647    648    649 \n",
      "     0      0      0 105000 192500  17500  20000      0 105000      0  35000 \n",
      "   650    651    652    653    654    655    656    657    658    659    660 \n",
      "     0 192500  35000  35000  20000 192500  20000  35000  17500  17500      0 \n",
      "   661    662    663    664    665    666    667    668    669    670    671 \n",
      " 35000      0  35000  35000  35000  35000  35000  20000  17500 192500  35000 \n",
      "   672    673    674    675    676    677    678    679    680    681    682 \n",
      "192500 192500 192500  17500 105000      0  17500  17500  35000      0 105000 \n",
      "   683    684    685    686    687    688    689    690    691    692    693 \n",
      "     0      0 105000 105000      0 105000  17500  17500      0  35000  35000 \n",
      "   694    695    696    697    698    699    700    701    702    703    704 \n",
      "     0  35000  20000  17500  35000  35000      0      0      0  17500  17500 \n",
      "   705    706    707    708    709    710    711    712    713    714    715 \n",
      "     0  17500  17500  17500  20000      0      0  35000      0 105000      0 \n",
      "   716    717    718    719    720    721    722    723    724    725    726 \n",
      "     0  17500      0  35000      0  35000      0  17500  20000      0  35000 \n",
      "   727    728    729    730    731    732    733    734    735    736    737 \n",
      "     0 105000      0  35000  35000 105000  35000  20000  20000  35000  20000 \n",
      "   738    739    740    741    742    743    744    745    746    747    748 \n",
      " 20000      0 105000      0      0  35000      0      0      0      0  35000 \n",
      "   749    750    751    752    753    754    755    756    757    758    759 \n",
      " 20000      0  20000  35000      0  20000      0  20000  17500  35000  35000 \n",
      "   760    761    762    763    764    765    766    767    768    769    770 \n",
      " 17500  35000      0  20000      0 105000      0  35000 192500      0      0 \n",
      "   771    772    773    774    775    776    777    778    779    780    781 \n",
      "     0  35000      0  17500  17500 192500      0  17500      0  20000      0 \n",
      "   782    783    784    785    786    787    788    789    790    791    792 \n",
      "     0  17500 192500  35000  35000  20000  17500  20000  17500      0 105000 \n",
      "   793    794    795    796    797    798    799    800    801    802    803 \n",
      "105000  35000 105000  17500  20000  35000      0  17500  17500 105000  20000 \n",
      "   804    805    806    807    808    809    810    811    812    813    814 \n",
      "     0  17500      0  35000  17500      0  35000 105000 192500 192500      0 \n",
      "   815    816    817    818    819    820    821    822    823    824    825 \n",
      "     0  35000      0      0  20000  35000  17500 105000  35000  17500  20000 \n",
      "   826    827    828    829    830    831    832    833    834    835    836 \n",
      "105000  35000      0  35000      0      0  35000  35000  17500 105000  17500 \n",
      "   837    838    839    840    841    842    843    844    845    846    847 \n",
      " 17500  35000  17500 192500      0  35000  20000  35000 105000  20000      0 \n",
      "   848    849    850    851    852    853    854    855    856    857    858 \n",
      " 35000  35000 192500      0 105000      0  35000  20000      0  35000      0 \n",
      "   859    860    861    862    863    864    865    866    867    868    869 \n",
      " 17500      0  20000      0  20000      0  20000  20000  17500      0  17500 \n",
      "   870    871    872    873    874    875    876    877    878    879    880 \n",
      "192500  35000  17500      0      0  20000      0      0      0      0      0 \n",
      "   881    882    883    884    885    886    887    888    889    890    891 \n",
      "105000      0      0      0      0      0      0      0      0      0      0 \n",
      "   892    893    894    895    896    897    898    899    900    901    902 \n",
      "     0      0      0      0      0      0  35000      0      0 105000  35000 \n",
      "   903    904    905    906    907    908    909    910    911    912    913 \n",
      "     0      0  17500      0      0  35000      0      0  17500  20000  17500 \n",
      "   914    915    916    917    918    919    920    921    922    923    924 \n",
      " 35000 105000  20000  20000  20000 192500  20000      0  17500  35000      0 \n",
      "   925    926    927    928    929    930    931    932    933    934    935 \n",
      " 20000  17500      0      0  17500      0  17500  17500  17500  35000  17500 \n",
      "   936    937    938    939    940    941    942    943    944    945    946 \n",
      " 17500  17500      0      0      0      0  17500      0  20000 192500      0 \n",
      "   947    948    949    950    951    952    953    954    955    956    957 \n",
      "192500  35000  35000  35000      0 192500      0  35000      0  17500  17500 \n",
      "   958    959    960    961    962    963    964    965    966    967    968 \n",
      "     0  20000 192500 192500  17500      0      0      0      0      0      0 \n",
      "   969    970    971    972    973    974    975    976    977    978    979 \n",
      " 35000      0      0      0      0      0  20000  20000  35000  17500  17500 \n",
      "   980    981    982    983    984    985    986    987    988    989    990 \n",
      "192500  20000 105000 192500  17500  17500  35000  35000 192500  35000  35000 \n",
      "   991    992    993    994    995    996    997    998    999   1000 \n",
      " 17500      0 105000  20000      0      0      0  17500  17500  17500 \n",
      "16 Levels: 0 17500 20000 20200 22400 35000 38400 70000 89600 105000 ... 64750000\n"
     ]
    }
   ],
   "source": [
    "apprentissage <- read.table(\"apprentissage.csv\", sep = \",\" ,header = FALSE)\n",
    "test <- read.csv(\"test.csv\", sep = \",\" ,header = FALSE)\n",
    "# Remplacer les NA par des 0\n",
    "apprentissage[is.na(apprentissage)]<-0\n",
    "test[is.na(test)]<-0\n",
    "\n",
    "predictionChiffreAffaire = GetModelChiffreAffaires(apprentissage, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"generating new model ...\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in split.default(x = seq_len(nrow(x)), f = f, drop = drop, ...):\n",
      "\"la taille de données n'est pas un multiple de la variable découpée\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Error Rate > 0.3, WRONG MODEL\"\n",
      "[1] 0.9833333\n",
      "[1] \"generating new model ...\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in split.default(x = seq_len(nrow(x)), f = f, drop = drop, ...):\n",
      "\"la taille de données n'est pas un multiple de la variable découpée\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Error Rate > 0.3, WRONG MODEL\"\n",
      "[1] 0.9666667\n",
      "[1] \"generating new model ...\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in split.default(x = seq_len(nrow(x)), f = f, drop = drop, ...):\n",
      "\"la taille de données n'est pas un multiple de la variable découpée\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Error Rate > 0.3, WRONG MODEL\"\n",
      "[1] 0.85\n",
      "[1] \"generating new model ...\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in split.default(x = seq_len(nrow(x)), f = f, drop = drop, ...):\n",
      "\"la taille de données n'est pas un multiple de la variable découpée\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Error Rate > 0.3, WRONG MODEL\"\n",
      "[1] 0.8333333\n",
      "[1] \"generating new model ...\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in split.default(x = seq_len(nrow(x)), f = f, drop = drop, ...):\n",
      "\"la taille de données n'est pas un multiple de la variable découpée\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Error Rate > 0.3, WRONG MODEL\"\n",
      "[1] 0.8333333\n",
      "[1] \"generating new model ...\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in split.default(x = seq_len(nrow(x)), f = f, drop = drop, ...):\n",
      "\"la taille de données n'est pas un multiple de la variable découpée\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Error Rate > 0.3, WRONG MODEL\"\n",
      "[1] 0.8333333\n",
      "[1] \"generating new model ...\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in split.default(x = seq_len(nrow(x)), f = f, drop = drop, ...):\n",
      "\"la taille de données n'est pas un multiple de la variable découpée\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Error Rate > 0.3, WRONG MODEL\"\n",
      "[1] 0.6666667\n",
      "[1] \"generating new model ...\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in split.default(x = seq_len(nrow(x)), f = f, drop = drop, ...):\n",
      "\"la taille de données n'est pas un multiple de la variable découpée\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Error Rate > 0.3, WRONG MODEL\"\n",
      "[1] 0.8333333\n",
      "[1] \"generating new model ...\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in split.default(x = seq_len(nrow(x)), f = f, drop = drop, ...):\n",
      "\"la taille de données n'est pas un multiple de la variable découpée\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Error Rate > 0.3, WRONG MODEL\"\n",
      "[1] 0.9666667\n",
      "[1] \"generating new model ...\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in split.default(x = seq_len(nrow(x)), f = f, drop = drop, ...):\n",
      "\"la taille de données n'est pas un multiple de la variable découpée\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Error Rate > 0.3, WRONG MODEL\"\n",
      "[1] 1\n",
      "[1] \"generating new model ...\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in split.default(x = seq_len(nrow(x)), f = f, drop = drop, ...):\n",
      "\"la taille de données n'est pas un multiple de la variable découpée\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Error Rate > 0.3, WRONG MODEL\"\n",
      "[1] 0.9666667\n",
      "[1] \"generating new model ...\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in split.default(x = seq_len(nrow(x)), f = f, drop = drop, ...):\n",
      "\"la taille de données n'est pas un multiple de la variable découpée\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Error Rate > 0.3, WRONG MODEL\"\n",
      "[1] 0.8333333\n",
      "[1] \"generating new model ...\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in split.default(x = seq_len(nrow(x)), f = f, drop = drop, ...):\n",
      "\"la taille de données n'est pas un multiple de la variable découpée\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Error Rate > 0.3, WRONG MODEL\"\n",
      "[1] 0.85\n",
      "[1] \"generating new model ...\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in split.default(x = seq_len(nrow(x)), f = f, drop = drop, ...):\n",
      "\"la taille de données n'est pas un multiple de la variable découpée\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Error Rate > 0.3, WRONG MODEL\"\n",
      "[1] 0.9833333\n",
      "[1] \"generating new model ...\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in split.default(x = seq_len(nrow(x)), f = f, drop = drop, ...):\n",
      "\"la taille de données n'est pas un multiple de la variable découpée\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Error Rate > 0.3, WRONG MODEL\"\n",
      "[1] 1\n",
      "[1] \"generating new model ...\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in split.default(x = seq_len(nrow(x)), f = f, drop = drop, ...):\n",
      "\"la taille de données n'est pas un multiple de la variable découpée\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Error Rate > 0.3, WRONG MODEL\"\n",
      "[1] 0.95\n",
      "[1] \"generating new model ...\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in split.default(x = seq_len(nrow(x)), f = f, drop = drop, ...):\n",
      "\"la taille de données n'est pas un multiple de la variable découpée\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Error Rate > 0.3, WRONG MODEL\"\n",
      "[1] 0.9666667\n",
      "[1] \"generating new model ...\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in split.default(x = seq_len(nrow(x)), f = f, drop = drop, ...):\n",
      "\"la taille de données n'est pas un multiple de la variable découpée\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Error Rate > 0.3, WRONG MODEL\"\n",
      "[1] 1\n",
      "[1] \"generating new model ...\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in split.default(x = seq_len(nrow(x)), f = f, drop = drop, ...):\n",
      "\"la taille de données n'est pas un multiple de la variable découpée\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Error Rate > 0.3, WRONG MODEL\"\n",
      "[1] 1\n",
      "[1] \"generating new model ...\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in split.default(x = seq_len(nrow(x)), f = f, drop = drop, ...):\n",
      "\"la taille de données n'est pas un multiple de la variable découpée\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Error Rate > 0.3, WRONG MODEL\"\n",
      "[1] 0.9833333\n",
      "[1] \"generating new model ...\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in split.default(x = seq_len(nrow(x)), f = f, drop = drop, ...):\n",
      "\"la taille de données n'est pas un multiple de la variable découpée\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Error Rate > 0.3, WRONG MODEL\"\n",
      "[1] 0.9833333\n",
      "[1] \"generating new model ...\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in split.default(x = seq_len(nrow(x)), f = f, drop = drop, ...):\n",
      "\"la taille de données n'est pas un multiple de la variable découpée\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Error Rate < 0.3\"\n",
      "[1] 0.55\n",
      "[[1]]\n",
      "[1] 0.55\n",
      "\n",
      "[[2]]\n",
      "n= 25 \n",
      "\n",
      "node), split, n, loss, yval, (yprob)\n",
      "      * denotes terminal node\n",
      "\n",
      " 1) root 25 13 10000 (0.04 0.24 0.48 0.08 0.08 0.04 0.04)  \n",
      "   2) X30< 5.1 11  5 5000 (0 0.55 0.27 0 0.091 0 0.091)  \n",
      "     4) X2>=0.5 6  1 5000 (0 0.83 0 0 0.17 0 0) *\n",
      "     5) X2< 0.5 5  2 10000 (0 0.2 0.6 0 0 0 0.2)  \n",
      "      10) X6< 32.725 3  0 10000 (0 0 1 0 0 0 0) *\n",
      "      11) X6>=32.725 2  1 5000 (0 0.5 0 0 0 0 0.5) *\n",
      "   3) X30>=5.1 14  5 10000 (0.071 0 0.64 0.14 0.071 0.071 0)  \n",
      "     6) X15< 16.95 10  1 10000 (0.1 0 0.9 0 0 0 0) *\n",
      "     7) X15>=16.95 4  2 15000 (0 0 0 0.5 0.25 0.25 0) *\n",
      "\n",
      "    1     2     3     4     5     6     7     8     9    10    11    12    13 \n",
      "10000 15000 15000  5000 10000 15000  5000 15000  5000 15000 10000 10000 15000 \n",
      "   14    15    16    17    18    19    20    21    22    23    24    25    26 \n",
      " 5000 10000 10000 15000  5000 15000 10000  5000  5000  5000 10000 10000 10000 \n",
      "   27    28    29    30    31    32    33    34    35    36    37    38    39 \n",
      " 5000  5000  5000  5000 15000 15000 15000  5000  5000  5000  5000  5000 15000 \n",
      "   40    41    42    43    44    45    46    47    48    49    50    51    52 \n",
      " 5000  5000  5000  5000 15000  5000 10000  5000  5000 15000  5000  5000  5000 \n",
      "   53    54    55    56    57    58    59    60    61    62    63    64    65 \n",
      " 5000  5000  5000  5000 10000 10000 15000  5000 10000 10000 10000 15000 15000 \n",
      "   66    67    68    69    70    71    72    73    74    75    76    77    78 \n",
      "10000  5000 10000 10000 15000  5000 15000 15000  5000  5000 10000 10000 10000 \n",
      "   79    80    81    82    83    84    85    86    87    88    89    90    91 \n",
      "10000  5000 10000 10000 10000 10000 10000 15000 10000  5000 10000  5000  5000 \n",
      "   92    93    94    95    96    97    98    99   100   101   102   103   104 \n",
      "15000 10000 10000  5000 10000 15000  5000  5000 10000 15000 10000 15000  5000 \n",
      "  105   106   107   108   109   110   111   112   113   114   115   116   117 \n",
      " 5000 10000 10000 15000  5000 15000  5000 15000 10000 15000 10000 15000  5000 \n",
      "  118   119   120   121   122   123   124   125   126   127   128   129   130 \n",
      " 5000 10000 10000 10000 15000 10000  5000 10000 15000 15000 15000 10000 15000 \n",
      "  131   132   133   134   135   136   137   138   139   140   141   142   143 \n",
      " 5000  5000  5000  5000 15000 10000  5000  5000 15000  5000  5000  5000 10000 \n",
      "  144   145   146   147   148   149   150   151   152   153   154   155   156 \n",
      "10000  5000 15000 10000  5000 10000  5000 15000 15000 15000  5000 10000 15000 \n",
      "  157   158   159   160   161   162   163   164   165   166   167   168   169 \n",
      " 5000 15000  5000 10000  5000  5000 10000  5000 10000 10000  5000 10000 10000 \n",
      "  170   171   172   173   174   175   176   177   178   179   180   181   182 \n",
      "10000 10000 10000 10000 10000  5000 10000  5000 10000 15000 10000 10000 10000 \n",
      "  183   184   185   186   187   188   189   190   191   192   193   194   195 \n",
      "10000 15000 10000 15000 15000 15000  5000  5000 15000  5000  5000  5000 15000 \n",
      "  196   197   198   199   200   201   202   203   204   205   206   207   208 \n",
      "10000  5000  5000 10000  5000  5000  5000 10000 10000 15000 15000  5000  5000 \n",
      "  209   210   211   212   213   214   215   216   217   218   219   220   221 \n",
      " 5000 10000 10000 10000 10000 15000  5000  5000 10000  5000 10000  5000  5000 \n",
      "  222   223   224   225   226   227   228   229   230   231   232   233   234 \n",
      "15000 15000 15000 10000  5000  5000  5000 10000  5000 15000  5000  5000 10000 \n",
      "  235   236   237   238   239   240   241   242   243   244   245   246   247 \n",
      "10000 10000 10000 10000 10000 10000  5000 10000 10000 15000 10000 10000  5000 \n",
      "  248   249   250   251   252   253   254   255   256   257   258   259   260 \n",
      " 5000  5000 15000 10000 10000 10000  5000 15000 10000  5000 10000  5000  5000 \n",
      "  261   262   263   264   265   266   267   268   269   270   271   272   273 \n",
      "10000 10000 10000 10000  5000 15000 10000  5000  5000  5000  5000  5000 15000 \n",
      "  274   275   276   277   278   279   280   281   282   283   284   285   286 \n",
      "10000 10000 10000 10000  5000 10000 10000 10000 10000 15000  5000 15000 15000 \n",
      "  287   288   289   290   291   292   293   294   295   296   297   298   299 \n",
      "10000  5000 10000 15000 15000 15000 10000 10000 10000 10000  5000 10000 15000 \n",
      "  300   301   302   303   304   305   306   307   308   309   310   311   312 \n",
      "10000  5000  5000  5000 15000 10000 15000 10000  5000 10000 15000 10000 10000 \n",
      "  313   314   315   316   317   318   319   320   321   322   323   324   325 \n",
      "10000  5000 15000  5000  5000 10000  5000 10000 15000 10000  5000  5000 10000 \n",
      "  326   327   328   329   330   331   332   333   334   335   336   337   338 \n",
      " 5000 15000  5000 15000 15000 15000  5000 10000  5000 15000 15000 10000  5000 \n",
      "  339   340   341   342   343   344   345   346   347   348   349   350   351 \n",
      "15000  5000 15000  5000 15000  5000 10000  5000 15000  5000 10000  5000  5000 \n",
      "  352   353   354   355   356   357   358   359   360   361   362   363   364 \n",
      "15000  5000  5000  5000  5000 15000 10000 15000 15000  5000 10000  5000 15000 \n",
      "  365   366   367   368   369   370   371   372   373   374   375   376   377 \n",
      " 5000 10000 15000 10000  5000  5000  5000 15000 10000 10000  5000  5000 15000 \n",
      "  378   379   380   381   382   383   384   385   386   387   388   389   390 \n",
      "10000 10000  5000  5000  5000 15000 15000 10000 15000 10000 10000 10000  5000 \n",
      "  391   392   393   394   395   396   397   398   399   400   401   402   403 \n",
      "10000 10000 10000 10000  5000 10000  5000 10000  5000  5000 15000  5000  5000 \n",
      "  404   405   406   407   408   409   410   411   412   413   414   415   416 \n",
      "10000  5000  5000 10000 10000 10000  5000 10000 15000 10000  5000  5000 10000 \n",
      "  417   418   419   420   421   422   423   424   425   426   427   428   429 \n",
      "10000 10000  5000 10000 10000 10000  5000 10000 15000 10000 10000 10000  5000 \n",
      "  430   431   432   433   434   435   436   437   438   439   440   441   442 \n",
      "10000 10000 10000  5000 10000 10000 10000 10000 15000  5000 15000 10000 10000 \n",
      "  443   444   445   446   447   448   449   450   451   452   453   454   455 \n",
      " 5000 10000 10000 10000 10000 15000 10000  5000 15000 10000 10000 15000  5000 \n",
      "  456   457   458   459   460   461   462   463   464   465   466   467   468 \n",
      "10000 10000 15000 15000 10000 10000 10000 15000 10000 10000 15000  5000 10000 \n",
      "  469   470   471   472   473   474   475   476   477   478   479   480   481 \n",
      " 5000 15000 15000 10000 10000 10000 10000 10000 15000  5000 10000  5000 10000 \n",
      "  482   483   484   485   486   487   488   489   490   491   492   493   494 \n",
      "10000 10000 10000  5000 10000 15000  5000 10000  5000  5000 15000 15000  5000 \n",
      "  495   496   497   498   499   500   501   502   503   504   505   506   507 \n",
      "10000 10000 10000 10000 10000 10000 10000  5000  5000 15000 10000 10000 10000 \n",
      "  508   509   510   511   512   513   514   515   516   517   518   519   520 \n",
      " 5000 10000 10000 15000 10000 15000 10000 10000 10000 10000 10000 15000  5000 \n",
      "  521   522   523   524   525   526   527   528   529   530   531   532   533 \n",
      "10000 10000 10000  5000  5000 10000 10000 10000 10000 10000  5000 10000 10000 \n",
      "  534   535   536   537   538   539   540   541   542   543   544   545   546 \n",
      "10000 10000 10000 10000 10000 10000 10000 10000 10000 10000  5000 10000 10000 \n",
      "  547   548   549   550   551   552   553   554   555   556   557   558   559 \n",
      "10000 10000 10000 10000 10000 10000  5000 10000 10000 10000 10000 10000  5000 \n",
      "  560   561   562   563   564   565   566   567   568   569   570   571   572 \n",
      "10000  5000 10000  5000  5000 10000  5000 10000 10000 15000 15000 10000  5000 \n",
      "  573   574   575   576   577   578   579   580   581   582   583   584   585 \n",
      "10000  5000 15000 10000 10000 10000  5000  5000 10000 10000  5000 10000 10000 \n",
      "  586   587   588   589   590   591   592   593   594   595   596   597   598 \n",
      " 5000 10000 10000 10000 10000  5000 10000  5000 10000 10000 10000 15000 10000 \n",
      "  599   600   601   602   603   604   605   606   607   608   609   610   611 \n",
      "10000 10000 10000 15000  5000  5000  5000 15000 15000  5000 10000 15000 10000 \n",
      "  612   613   614   615   616   617   618   619   620   621   622   623   624 \n",
      " 5000  5000 10000  5000 10000  5000  5000  5000 10000  5000 15000  5000 10000 \n",
      "  625   626   627   628   629   630   631   632   633   634   635   636   637 \n",
      "10000 10000 15000  5000  5000  5000  5000 10000  5000  5000 10000 10000 15000 \n",
      "  638   639   640   641   642   643   644   645   646   647   648   649   650 \n",
      "10000 10000  5000 10000 15000  5000 10000  5000 15000  5000 10000 10000 10000 \n",
      "  651   652   653   654   655   656   657   658   659   660   661   662   663 \n",
      " 5000  5000 15000  5000  5000  5000  5000  5000  5000 10000 15000 15000 15000 \n",
      "  664   665   666   667   668   669   670   671   672   673   674   675   676 \n",
      " 5000  5000 10000 15000 10000 10000  5000 15000 10000  5000 15000 15000 15000 \n",
      "  677   678   679   680   681   682   683   684   685   686   687   688   689 \n",
      "10000 15000  5000  5000  5000  5000 10000 15000 15000 15000 10000 10000  5000 \n",
      "  690   691   692   693   694   695   696   697   698   699   700   701   702 \n",
      " 5000 15000 10000  5000 15000 10000 10000 15000 15000 10000 15000 10000 10000 \n",
      "  703   704   705   706   707   708   709   710   711   712   713   714   715 \n",
      "15000 15000 10000  5000 15000  5000 15000 10000 10000 10000 10000 10000 10000 \n",
      "  716   717   718   719   720   721   722   723   724   725   726   727   728 \n",
      "10000  5000 10000  5000 10000  5000 15000  5000 10000 10000  5000 10000  5000 \n",
      "  729   730   731   732   733   734   735   736   737   738   739   740   741 \n",
      "15000  5000 10000  5000 10000  5000  5000  5000 10000  5000 15000  5000 10000 \n",
      "  742   743   744   745   746   747   748   749   750   751   752   753   754 \n",
      "15000  5000 10000 10000 10000 10000  5000 10000 15000 10000  5000 15000 15000 \n",
      "  755   756   757   758   759   760   761   762   763   764   765   766   767 \n",
      "10000 10000  5000 10000  5000  5000 10000 10000  5000 10000 10000  5000 15000 \n",
      "  768   769   770   771   772   773   774   775   776   777   778   779   780 \n",
      " 5000 10000 15000  5000  5000 10000 10000 15000 15000  5000  5000 10000 10000 \n",
      "  781   782   783   784   785   786   787   788   789   790   791   792   793 \n",
      " 5000 10000  5000 10000  5000 15000 10000 10000 15000  5000 10000  5000 15000 \n",
      "  794   795   796   797   798   799   800   801   802   803   804   805   806 \n",
      " 5000  5000  5000  5000  5000 10000  5000 15000  5000  5000 10000  5000 10000 \n",
      "  807   808   809   810   811   812   813   814   815   816   817   818   819 \n",
      " 5000 15000 10000 10000 10000  5000  5000 10000  5000  5000 10000 10000  5000 \n",
      "  820   821   822   823   824   825   826   827   828   829   830   831   832 \n",
      " 5000 15000 15000 15000 10000  5000 15000 10000 10000  5000 10000 10000 10000 \n",
      "  833   834   835   836   837   838   839   840   841   842   843   844   845 \n",
      "10000  5000  5000 10000 10000  5000  5000 15000 10000 10000 10000 15000  5000 \n",
      "  846   847   848   849   850   851   852   853   854   855   856   857   858 \n",
      "10000 10000 10000 10000  5000 10000 15000 15000  5000 10000 10000  5000 10000 \n",
      "  859   860   861   862   863   864   865   866   867   868   869   870   871 \n",
      "10000 15000  5000 10000  5000 15000 15000 10000  5000  5000  5000  5000  5000 \n",
      "  872   873   874   875   876   877   878   879   880   881   882   883   884 \n",
      " 5000 10000 10000 10000 10000 10000 10000  5000  5000  5000  5000  5000  5000 \n",
      "  885   886   887   888   889   890   891   892   893   894   895   896   897 \n",
      " 5000  5000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 \n",
      "  898   899   900   901   902   903   904   905   906   907   908   909   910 \n",
      " 5000 10000  5000  5000  5000  5000  5000 10000 10000 10000  5000 10000 10000 \n",
      "  911   912   913   914   915   916   917   918   919   920   921   922   923 \n",
      " 5000  5000  5000 15000  5000 15000 10000 10000  5000 15000 10000  5000  5000 \n",
      "  924   925   926   927   928   929   930   931   932   933   934   935   936 \n",
      " 5000 10000  5000 10000 15000  5000 10000  5000 15000 15000  5000 10000 10000 \n",
      "  937   938   939   940   941   942   943   944   945   946   947   948   949 \n",
      " 5000  5000 10000  5000 10000  5000 10000  5000  5000  5000  5000  5000 10000 \n",
      "  950   951   952   953   954   955   956   957   958   959   960   961   962 \n",
      " 5000 10000  5000 10000  5000 10000  5000 10000  5000  5000  5000  5000 10000 \n",
      "  963   964   965   966   967   968   969   970   971   972   973   974   975 \n",
      " 5000 10000 10000 10000 10000 10000  5000  5000 10000 10000 10000 10000  5000 \n",
      "  976   977   978   979   980   981   982   983   984   985   986   987   988 \n",
      " 5000  5000  5000  5000  5000  5000  5000  5000  5000  5000  5000  5000  5000 \n",
      "  989   990   991   992   993   994   995   996   997   998   999  1000 \n",
      " 5000  5000  5000 10000  5000  5000 10000 10000  5000  5000  5000  5000 \n",
      "Levels: 0 5000 10000 15000 20000 30000 35000\n"
     ]
    }
   ],
   "source": [
    "predictionCapaciteEmprunt = GetModelCapaciteEmprunt(apprentissage, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"generating new model ...\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in split.default(x = seq_len(nrow(x)), f = f, drop = drop, ...):\n",
      "\"la taille de données n'est pas un multiple de la variable découpée\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Error Rate < 0.3\"\n",
      "[1] 0.3\n",
      "[[1]]\n",
      "[1] 0.3\n",
      "\n",
      "[[2]]\n",
      "n= 25 \n",
      "\n",
      "node), split, n, loss, yval, (yprob)\n",
      "      * denotes terminal node\n",
      "\n",
      "1) root 25 2 0 (0.9200000 0.0800000)  \n",
      "  2) X15< 3929.665 23 0 0 (1.0000000 0.0000000) *\n",
      "  3) X15>=3929.665 2 0 1 (0.0000000 1.0000000) *\n",
      "\n",
      "   1    2    3    4    5    6    7    8    9   10   11   12   13   14   15   16 \n",
      "   0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0 \n",
      "  17   18   19   20   21   22   23   24   25   26   27   28   29   30   31   32 \n",
      "   0    0    1    0    1    0    1    0    0    0    0    0    0    0    1    0 \n",
      "  33   34   35   36   37   38   39   40   41   42   43   44   45   46   47   48 \n",
      "   0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0 \n",
      "  49   50   51   52   53   54   55   56   57   58   59   60   61   62   63   64 \n",
      "   0    0    0    0    0    1    0    0    0    0    1    0    0    0    0    0 \n",
      "  65   66   67   68   69   70   71   72   73   74   75   76   77   78   79   80 \n",
      "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "  81   82   83   84   85   86   87   88   89   90   91   92   93   94   95   96 \n",
      "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "  97   98   99  100  101  102  103  104  105  106  107  108  109  110  111  112 \n",
      "   1    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0 \n",
      " 113  114  115  116  117  118  119  120  121  122  123  124  125  126  127  128 \n",
      "   0    0    0    1    0    0    0    0    0    1    0    0    0    0    1    0 \n",
      " 129  130  131  132  133  134  135  136  137  138  139  140  141  142  143  144 \n",
      "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      " 145  146  147  148  149  150  151  152  153  154  155  156  157  158  159  160 \n",
      "   0    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      " 161  162  163  164  165  166  167  168  169  170  171  172  173  174  175  176 \n",
      "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      " 177  178  179  180  181  182  183  184  185  186  187  188  189  190  191  192 \n",
      "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      " 193  194  195  196  197  198  199  200  201  202  203  204  205  206  207  208 \n",
      "   0    0    1    0    0    0    0    0    0    0    0    0    0    1    0    1 \n",
      " 209  210  211  212  213  214  215  216  217  218  219  220  221  222  223  224 \n",
      "   0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0 \n",
      " 225  226  227  228  229  230  231  232  233  234  235  236  237  238  239  240 \n",
      "   0    0    0    1    0    0    1    0    0    0    0    0    0    0    0    0 \n",
      " 241  242  243  244  245  246  247  248  249  250  251  252  253  254  255  256 \n",
      "   0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0 \n",
      " 257  258  259  260  261  262  263  264  265  266  267  268  269  270  271  272 \n",
      "   0    0    0    0    0    0    0    0    0    0    0    0    1    1    1    0 \n",
      " 273  274  275  276  277  278  279  280  281  282  283  284  285  286  287  288 \n",
      "   0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0 \n",
      " 289  290  291  292  293  294  295  296  297  298  299  300  301  302  303  304 \n",
      "   0    0    1    1    0    0    0    0    0    0    1    0    1    1    1    0 \n",
      " 305  306  307  308  309  310  311  312  313  314  315  316  317  318  319  320 \n",
      "   0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0 \n",
      " 321  322  323  324  325  326  327  328  329  330  331  332  333  334  335  336 \n",
      "   0    0    1    0    0    0    1    0    0    0    0    0    0    0    0    0 \n",
      " 337  338  339  340  341  342  343  344  345  346  347  348  349  350  351  352 \n",
      "   0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0 \n",
      " 353  354  355  356  357  358  359  360  361  362  363  364  365  366  367  368 \n",
      "   0    0    0    0    0    0    1    1    0    0    0    0    0    0    0    0 \n",
      " 369  370  371  372  373  374  375  376  377  378  379  380  381  382  383  384 \n",
      "   0    0    0    0    0    0    0    0    0    0    0    0    1    0    1    0 \n",
      " 385  386  387  388  389  390  391  392  393  394  395  396  397  398  399  400 \n",
      "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      " 401  402  403  404  405  406  407  408  409  410  411  412  413  414  415  416 \n",
      "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      " 417  418  419  420  421  422  423  424  425  426  427  428  429  430  431  432 \n",
      "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      " 433  434  435  436  437  438  439  440  441  442  443  444  445  446  447  448 \n",
      "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      " 449  450  451  452  453  454  455  456  457  458  459  460  461  462  463  464 \n",
      "   0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      " 465  466  467  468  469  470  471  472  473  474  475  476  477  478  479  480 \n",
      "   0    1    0    0    0    1    0    0    0    0    0    0    0    1    0    0 \n",
      " 481  482  483  484  485  486  487  488  489  490  491  492  493  494  495  496 \n",
      "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      " 497  498  499  500  501  502  503  504  505  506  507  508  509  510  511  512 \n",
      "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      " 513  514  515  516  517  518  519  520  521  522  523  524  525  526  527  528 \n",
      "   0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0 \n",
      " 529  530  531  532  533  534  535  536  537  538  539  540  541  542  543  544 \n",
      "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      " 545  546  547  548  549  550  551  552  553  554  555  556  557  558  559  560 \n",
      "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      " 561  562  563  564  565  566  567  568  569  570  571  572  573  574  575  576 \n",
      "   0    0    0    0    0    1    0    0    0    1    0    0    0    0    0    0 \n",
      " 577  578  579  580  581  582  583  584  585  586  587  588  589  590  591  592 \n",
      "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      " 593  594  595  596  597  598  599  600  601  602  603  604  605  606  607  608 \n",
      "   0    0    0    0    0    0    0    0    0    0    0    0    1    1    0    0 \n",
      " 609  610  611  612  613  614  615  616  617  618  619  620  621  622  623  624 \n",
      "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      " 625  626  627  628  629  630  631  632  633  634  635  636  637  638  639  640 \n",
      "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      " 641  642  643  644  645  646  647  648  649  650  651  652  653  654  655  656 \n",
      "   0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0 \n",
      " 657  658  659  660  661  662  663  664  665  666  667  668  669  670  671  672 \n",
      "   0    0    0    0    1    0    0    0    0    0    1    0    0    0    0    0 \n",
      " 673  674  675  676  677  678  679  680  681  682  683  684  685  686  687  688 \n",
      "   0    0    1    1    0    0    0    1    0    1    0    1    0    0    0    0 \n",
      " 689  690  691  692  693  694  695  696  697  698  699  700  701  702  703  704 \n",
      "   0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0 \n",
      " 705  706  707  708  709  710  711  712  713  714  715  716  717  718  719  720 \n",
      "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      " 721  722  723  724  725  726  727  728  729  730  731  732  733  734  735  736 \n",
      "   0    0    0    0    0    1    0    0    0    0    0    1    0    0    1    0 \n",
      " 737  738  739  740  741  742  743  744  745  746  747  748  749  750  751  752 \n",
      "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1 \n",
      " 753  754  755  756  757  758  759  760  761  762  763  764  765  766  767  768 \n",
      "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      " 769  770  771  772  773  774  775  776  777  778  779  780  781  782  783  784 \n",
      "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      " 785  786  787  788  789  790  791  792  793  794  795  796  797  798  799  800 \n",
      "   0    0    0    0    0    0    0    0    0    0    1    0    0    1    0    0 \n",
      " 801  802  803  804  805  806  807  808  809  810  811  812  813  814  815  816 \n",
      "   0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      " 817  818  819  820  821  822  823  824  825  826  827  828  829  830  831  832 \n",
      "   0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0 \n",
      " 833  834  835  836  837  838  839  840  841  842  843  844  845  846  847  848 \n",
      "   0    1    0    0    0    0    1    0    0    0    0    0    0    0    0    0 \n",
      " 849  850  851  852  853  854  855  856  857  858  859  860  861  862  863  864 \n",
      "   0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      " 865  866  867  868  869  870  871  872  873  874  875  876  877  878  879  880 \n",
      "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      " 881  882  883  884  885  886  887  888  889  890  891  892  893  894  895  896 \n",
      "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      " 897  898  899  900  901  902  903  904  905  906  907  908  909  910  911  912 \n",
      "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      " 913  914  915  916  917  918  919  920  921  922  923  924  925  926  927  928 \n",
      "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      " 929  930  931  932  933  934  935  936  937  938  939  940  941  942  943  944 \n",
      "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      " 945  946  947  948  949  950  951  952  953  954  955  956  957  958  959  960 \n",
      "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      " 961  962  963  964  965  966  967  968  969  970  971  972  973  974  975  976 \n",
      "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      " 977  978  979  980  981  982  983  984  985  986  987  988  989  990  991  992 \n",
      "   0    0    0    0    0    0    0    0    0    0    1    0    0    1    0    0 \n",
      " 993  994  995  996  997  998  999 1000 \n",
      "   0    0    0    0    0    0    0    0 \n",
      "Levels: 0 1\n"
     ]
    }
   ],
   "source": [
    "predictionSecteurOne = GetModelSecteurOne(apprentissage, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"generating new model ...\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in split.default(x = seq_len(nrow(x)), f = f, drop = drop, ...):\n",
      "\"la taille de données n'est pas un multiple de la variable découpée\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Error Rate < 0.3\"\n",
      "[1] 0.1833333\n",
      "[[1]]\n",
      "[1] 0.1833333\n",
      "\n",
      "[[2]]\n",
      "n= 25 \n",
      "\n",
      "node), split, n, loss, yval, (yprob)\n",
      "      * denotes terminal node\n",
      "\n",
      " 1) root 25 5 0 (0.8000000 0.2000000)  \n",
      "   2) X14< 7818.15 23 3 0 (0.8695652 0.1304348)  \n",
      "     4) X9>=4.225 13 0 0 (1.0000000 0.0000000) *\n",
      "     5) X9< 4.225 10 3 0 (0.7000000 0.3000000)  \n",
      "      10) X23< 67.605 8 1 0 (0.8750000 0.1250000) *\n",
      "      11) X23>=67.605 2 0 1 (0.0000000 1.0000000) *\n",
      "   3) X14>=7818.15 2 0 1 (0.0000000 1.0000000) *\n",
      "\n",
      "   1    2    3    4    5    6    7    8    9   10   11   12   13   14   15   16 \n",
      "   0    0    0    0    0    0    0    0    0    0    1    0    1    0    0    1 \n",
      "  17   18   19   20   21   22   23   24   25   26   27   28   29   30   31   32 \n",
      "   0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0 \n",
      "  33   34   35   36   37   38   39   40   41   42   43   44   45   46   47   48 \n",
      "   0    0    0    1    0    0    0    0    1    0    1    0    0    0    1    0 \n",
      "  49   50   51   52   53   54   55   56   57   58   59   60   61   62   63   64 \n",
      "   1    0    0    0    0    0    0    0    1    0    0    1    0    0    0    0 \n",
      "  65   66   67   68   69   70   71   72   73   74   75   76   77   78   79   80 \n",
      "   0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0 \n",
      "  81   82   83   84   85   86   87   88   89   90   91   92   93   94   95   96 \n",
      "   0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0 \n",
      "  97   98   99  100  101  102  103  104  105  106  107  108  109  110  111  112 \n",
      "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      " 113  114  115  116  117  118  119  120  121  122  123  124  125  126  127  128 \n",
      "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      " 129  130  131  132  133  134  135  136  137  138  139  140  141  142  143  144 \n",
      "   0    0    0    1    0    0    0    1    0    0    0    0    0    1    0    0 \n",
      " 145  146  147  148  149  150  151  152  153  154  155  156  157  158  159  160 \n",
      "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      " 161  162  163  164  165  166  167  168  169  170  171  172  173  174  175  176 \n",
      "   0    0    0    0    0    0    0    1    0    1    0    0    0    0    0    0 \n",
      " 177  178  179  180  181  182  183  184  185  186  187  188  189  190  191  192 \n",
      "   0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0 \n",
      " 193  194  195  196  197  198  199  200  201  202  203  204  205  206  207  208 \n",
      "   0    0    0    0    1    0    0    0    1    0    0    1    0    0    0    0 \n",
      " 209  210  211  212  213  214  215  216  217  218  219  220  221  222  223  224 \n",
      "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      " 225  226  227  228  229  230  231  232  233  234  235  236  237  238  239  240 \n",
      "   0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    1 \n",
      " 241  242  243  244  245  246  247  248  249  250  251  252  253  254  255  256 \n",
      "   0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      " 257  258  259  260  261  262  263  264  265  266  267  268  269  270  271  272 \n",
      "   0    0    0    0    0    0    0    1    0    1    0    0    0    0    0    0 \n",
      " 273  274  275  276  277  278  279  280  281  282  283  284  285  286  287  288 \n",
      "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      " 289  290  291  292  293  294  295  296  297  298  299  300  301  302  303  304 \n",
      "   0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0 \n",
      " 305  306  307  308  309  310  311  312  313  314  315  316  317  318  319  320 \n",
      "   0    0    0    0    0    1    0    1    0    0    0    0    0    0    0    0 \n",
      " 321  322  323  324  325  326  327  328  329  330  331  332  333  334  335  336 \n",
      "   0    1    1    0    0    0    0    0    0    1    0    0    0    0    0    0 \n",
      " 337  338  339  340  341  342  343  344  345  346  347  348  349  350  351  352 \n",
      "   0    0    0    1    1    0    0    0    0    0    0    0    0    0    0    0 \n",
      " 353  354  355  356  357  358  359  360  361  362  363  364  365  366  367  368 \n",
      "   0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0 \n",
      " 369  370  371  372  373  374  375  376  377  378  379  380  381  382  383  384 \n",
      "   0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0 \n",
      " 385  386  387  388  389  390  391  392  393  394  395  396  397  398  399  400 \n",
      "   1    0    0    1    0    1    1    1    0    0    0    0    1    0    0    0 \n",
      " 401  402  403  404  405  406  407  408  409  410  411  412  413  414  415  416 \n",
      "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0 \n",
      " 417  418  419  420  421  422  423  424  425  426  427  428  429  430  431  432 \n",
      "   0    0    0    0    0    0    0    1    0    0    0    0    0    0    1    0 \n",
      " 433  434  435  436  437  438  439  440  441  442  443  444  445  446  447  448 \n",
      "   0    0    0    0    0    1    1    0    0    0    0    0    1    0    0    0 \n",
      " 449  450  451  452  453  454  455  456  457  458  459  460  461  462  463  464 \n",
      "   1    0    0    0    1    0    0    0    0    0    0    1    0    1    0    0 \n",
      " 465  466  467  468  469  470  471  472  473  474  475  476  477  478  479  480 \n",
      "   0    0    0    0    1    0    1    0    0    0    0    0    0    0    0    0 \n",
      " 481  482  483  484  485  486  487  488  489  490  491  492  493  494  495  496 \n",
      "   0    0    0    0    0    0    1    0    0    0    0    0    0    0    1    1 \n",
      " 497  498  499  500  501  502  503  504  505  506  507  508  509  510  511  512 \n",
      "   0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0 \n",
      " 513  514  515  516  517  518  519  520  521  522  523  524  525  526  527  528 \n",
      "   0    0    1    0    0    0    1    0    0    0    0    1    0    0    1    0 \n",
      " 529  530  531  532  533  534  535  536  537  538  539  540  541  542  543  544 \n",
      "   0    1    0    0    0    1    1    0    1    1    0    0    0    1    0    0 \n",
      " 545  546  547  548  549  550  551  552  553  554  555  556  557  558  559  560 \n",
      "   0    0    0    0    0    0    1    0    0    0    0    0    0    1    0    0 \n",
      " 561  562  563  564  565  566  567  568  569  570  571  572  573  574  575  576 \n",
      "   0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0 \n",
      " 577  578  579  580  581  582  583  584  585  586  587  588  589  590  591  592 \n",
      "   1    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0 \n",
      " 593  594  595  596  597  598  599  600  601  602  603  604  605  606  607  608 \n",
      "   0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    1 \n",
      " 609  610  611  612  613  614  615  616  617  618  619  620  621  622  623  624 \n",
      "   0    0    0    0    0    0    0    0    0    1    0    0    0    1    0    0 \n",
      " 625  626  627  628  629  630  631  632  633  634  635  636  637  638  639  640 \n",
      "   0    0    0    0    1    0    0    0    1    0    1    1    0    1    0    0 \n",
      " 641  642  643  644  645  646  647  648  649  650  651  652  653  654  655  656 \n",
      "   1    1    0    0    1    0    0    0    0    0    0    0    0    0    0    0 \n",
      " 657  658  659  660  661  662  663  664  665  666  667  668  669  670  671  672 \n",
      "   0    1    0    0    0    0    0    1    0    0    0    0    0    1    0    0 \n",
      " 673  674  675  676  677  678  679  680  681  682  683  684  685  686  687  688 \n",
      "   0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0 \n",
      " 689  690  691  692  693  694  695  696  697  698  699  700  701  702  703  704 \n",
      "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      " 705  706  707  708  709  710  711  712  713  714  715  716  717  718  719  720 \n",
      "   0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0 \n",
      " 721  722  723  724  725  726  727  728  729  730  731  732  733  734  735  736 \n",
      "   0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0 \n",
      " 737  738  739  740  741  742  743  744  745  746  747  748  749  750  751  752 \n",
      "   0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0 \n",
      " 753  754  755  756  757  758  759  760  761  762  763  764  765  766  767  768 \n",
      "   1    0    0    1    0    0    0    0    0    0    0    0    0    0    0    1 \n",
      " 769  770  771  772  773  774  775  776  777  778  779  780  781  782  783  784 \n",
      "   0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    1 \n",
      " 785  786  787  788  789  790  791  792  793  794  795  796  797  798  799  800 \n",
      "   0    0    0    0    1    0    0    0    0    0    0    0    0    1    1    0 \n",
      " 801  802  803  804  805  806  807  808  809  810  811  812  813  814  815  816 \n",
      "   0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0 \n",
      " 817  818  819  820  821  822  823  824  825  826  827  828  829  830  831  832 \n",
      "   0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0 \n",
      " 833  834  835  836  837  838  839  840  841  842  843  844  845  846  847  848 \n",
      "   0    0    1    0    0    0    0    0    0    0    0    0    0    1    0    0 \n",
      " 849  850  851  852  853  854  855  856  857  858  859  860  861  862  863  864 \n",
      "   0    0    0    0    0    1    1    0    0    0    0    0    1    0    0    0 \n",
      " 865  866  867  868  869  870  871  872  873  874  875  876  877  878  879  880 \n",
      "   0    0    0    0    0    0    0    0    0    0    1    0    1    0    0    1 \n",
      " 881  882  883  884  885  886  887  888  889  890  891  892  893  894  895  896 \n",
      "   1    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      " 897  898  899  900  901  902  903  904  905  906  907  908  909  910  911  912 \n",
      "   0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0 \n",
      " 913  914  915  916  917  918  919  920  921  922  923  924  925  926  927  928 \n",
      "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      " 929  930  931  932  933  934  935  936  937  938  939  940  941  942  943  944 \n",
      "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      " 945  946  947  948  949  950  951  952  953  954  955  956  957  958  959  960 \n",
      "   0    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      " 961  962  963  964  965  966  967  968  969  970  971  972  973  974  975  976 \n",
      "   1    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0 \n",
      " 977  978  979  980  981  982  983  984  985  986  987  988  989  990  991  992 \n",
      "   0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0 \n",
      " 993  994  995  996  997  998  999 1000 \n",
      "   0    0    0    0    1    0    0    0 \n",
      "Levels: 0 1\n"
     ]
    }
   ],
   "source": [
    "predictionSecteurTwo = GetModelSecteurTwo(apprentissage, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"generating new model ...\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in split.default(x = seq_len(nrow(x)), f = f, drop = drop, ...):\n",
      "\"la taille de données n'est pas un multiple de la variable découpée\""
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in cbind(yval2, yprob, nodeprob): le nombre de lignes des matrices doit correspondre (voir argument 2)\n",
     "output_type": "error",
     "traceback": [
      "Error in cbind(yval2, yprob, nodeprob): le nombre de lignes des matrices doit correspondre (voir argument 2)\nTraceback:\n",
      "1. GetModelSecteurParticulier(apprentissage, 10)",
      "2. validationCroiseeGetModel(donneesAppr, partitions, \"X1\")   # at line 482 of file <text>",
      "3. rpart(modalData_step2$X1 ~ ., modalData_step2, method = \"class\", \n .     control = rpart.control(minsplit = 5, cp = 0))   # at line 353 of file <text>",
      "4. cbind(yval2, yprob, nodeprob)"
     ]
    }
   ],
   "source": [
    "predictionSecteurParticulier = GetModelSecteurParticulier(apprentissage, 10)\n",
    "apprentissage\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
