{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in library(rpart): there is no package called 'rpart'\n",
     "output_type": "error",
     "traceback": [
      "Error in library(rpart): there is no package called 'rpart'\nTraceback:\n",
      "1. library(rpart)",
      "2. stop(txt, domain = NA)"
     ]
    }
   ],
   "source": [
    "\n",
    "#Objectifs:\n",
    "#  Programmer sous R:\n",
    "#    1) Une fonction pour la (TRAIN-TEST) validation répétée\n",
    "#    2) Une fonction pour la validation croisée (K feuilles)\n",
    "#    3) Une fonction pour la validation croisée imbriquée\n",
    "#    4) Une fonction pour le Leave One Out (avec k = n)\n",
    "# \n",
    "# deux critères à valider: moyenne des performances et écart-type des \n",
    "\n",
    "# construction de modèles (ou librairies de notre choix):\n",
    "# library(rpart) = algos de décisions -> CART: classification and regression tree (classif ou regression)\n",
    "# library(MASS) = algo de décisions -> LDA : linear decision analysis: (classif binaire)\n",
    "# library(FNN) : K plus proche voisin (k-PPV)\n",
    "# tree <- rpart(X10 ~ ., data= mesData, method= 'class')  ici ~ = en fonction de et . = toutes les autres variables\n",
    "# tree <- rpart(X10 ~ ., data= mesData, method= 'class', control=rpart.control(minsplit=50), cp= val entre 0 et 1)  ici ~ = en fonction de et . = toutes les autres variables\n",
    "# predict(tree, mesNouvellesDonnées, type='class')\n",
    "# predict(tree, mesNouvellesDonnées, type='prob')\n",
    "# JEUX de données madoc: Breiman: wave5000\n",
    "\n",
    "# attente livrable: les fonctions, mini rapport explication fonction et comparaison des modèles(1,2,3,4) :robustesse sur les données de Breiman\n",
    "\n",
    "# en sortie un vecteur mélanger de 1 à n: en entré un entier\n",
    "# fonction sample déjà défini\n",
    "\n",
    "\n",
    "# Question 1\n",
    "#data = dataframe avec une colonne réel\n",
    "#k = le nombre de répétition\n",
    "#predictColumn = string = nom de la colonne X10\n",
    "library(rpart)\n",
    "validationRepeteeRPART = function (data, k) {\n",
    "  errorRate = c();\n",
    "  for (i in 1:k) {\n",
    "    #on mélange les données\n",
    "    randomData = data[sample(nrow(data)),]\n",
    "    #les 20% premières lignes sont les données de tests\n",
    "    testData = randomData[1: 1000,]\n",
    "    #les 80% autres sont les données pour la construction de modèle\n",
    "    modalData = randomData[1000:nrow(data),]\n",
    "    #on calcule la précision (le taux d'erreurs)\n",
    "    tree = rpart(modalData$X10~.,modalData, method=\"class\")\n",
    "    prediction = predict(tree, testData, type=\"class\")\n",
    "    \n",
    "    #utiliser predict pour trouver le taux d'erreur entre data et predict puis utiliser table\n",
    "    contingencyTable = table(testData$X10, prediction)\n",
    "    \n",
    "    #dans une matrice de confusion, les individus en diagonale sont les biens classés donc pour avoir le taux d'erreur on calcule la somme de tous les autres cases/la somme totale de toutes les cases\n",
    "    sumError = 0\n",
    "    total = 0\n",
    "    for (i in 1:nrow(contingencyTable)) {\n",
    "      for (j in 1:ncol(contingencyTable)) {\n",
    "        if (i != j) {\n",
    "          sumError = sumError + contingencyTable[i,j]\n",
    "        }\n",
    "        total = total + contingencyTable[i,j]\n",
    "      }\n",
    "    }\n",
    "    errorRate = c(errorRate, c(sumError/total))\n",
    "  }\n",
    "  return(mean(errorRate))\n",
    "}\n",
    "\n",
    "library(MASS)\n",
    "\n",
    "validationRepeteeLDA = function (data, k) {\n",
    "  errorRate = c()\n",
    "  for (i in 1:k) {\n",
    "    #on mélange les données\n",
    "    randomData = data[sample(nrow(data)),]\n",
    "    #les 20% premières lignes sont les données de tests\n",
    "    testData = randomData[1: 1000,]\n",
    "    #les 80% autres sont les données pour la construction de modèle\n",
    "    modalData = randomData[1000:nrow(data),]\n",
    "    #on calcule la précision (le taux d'erreurs)\n",
    "    tree = lda(modalData$X10~.,modalData, method=\"moment\")\n",
    "    prediction = predict(tree, testData, type=\"moment\")\n",
    "    #utiliser predict pour trouver le taux d'erreur entre data et predict puis utiliser table\n",
    "    contingencyTable = table(testData$X10, prediction$class)\n",
    "    #dans une matrice de confusion, les individus en diagonale sont les biens classés donc pour avoir le taux d'erreur on calcule la somme de tous les autres cases/la somme totale de toutes les cases\n",
    "    sumError = 0\n",
    "    total = 0\n",
    "    for (i in 1:nrow(contingencyTable)) {\n",
    "      for (j in 1:ncol(contingencyTable)) {\n",
    "        if (i != j) {\n",
    "          sumError = sumError + contingencyTable[i,j]\n",
    "        }\n",
    "        total = total + contingencyTable[i,j]\n",
    "      }\n",
    "    }\n",
    "    errorRate = c(errorRate, c(sumError/total))\n",
    "  }\n",
    "  return(mean(errorRate))\n",
    "}\n",
    "\n",
    "#Exercice 2\n",
    "#data = dataframe\n",
    "#partitions = integer\n",
    "validationCroiseeRPART = function(data, partitions, metric) {\n",
    "  errorRate = c()\n",
    "  #on mélange les données\n",
    "  randomData = data[sample(nrow(data)),]\n",
    "  #list\n",
    "  setPartitions = split(randomData, 1:partitions)\n",
    "  for (i in 1:(partitions)) {\n",
    "    tempSetPartitions = setPartitions\n",
    "    currentTestData = setPartitions[[i]]\n",
    "    currentModalDataList = tempSetPartitions[-i]\n",
    "    #fusion dataframe\n",
    "    currentModalData = rbind.data.frame(currentModalDataList[[1]], currentModalDataList[[2]])\n",
    "    \n",
    "    for (j in 3:(partitions-1)) {\n",
    "      currentModalData = rbind.data.frame(currentModalData, currentModalDataList[[j]])\n",
    "    }\n",
    "    \n",
    "    numOfLinesTestCurrentModalData = as.integer(length(currentModalData)*0.2)\n",
    "    numOflinesModalCurrentModalData = as.integer(length(currentModalData)*0.8)\n",
    "    \n",
    "    testData_step2 = currentModalData[1:numOfLinesTestCurrentModalData,]\n",
    "    modalData_step2 = currentModalData[numOfLinesTestCurrentModalData+1:numOflinesModalCurrentModalData,]\n",
    "    \n",
    "    #on calcule la précision (le taux d'erreurs)\n",
    "    tree = rpart(modalData_step2$X10~.,modalData_step2, method=\"class\")\n",
    "    prediction = predict(tree, testData_step2, type=\"class\")\n",
    "    #utiliser predict pour trouver le taux d'erreur entre data et predict puis utiliser table\n",
    "    contingencyTable = table(testData_step2$X10, prediction)\n",
    "    \n",
    "    total = 0\n",
    "    sumError = 0\n",
    "    for (i in 1:nrow(contingencyTable)) {\n",
    "      for (j in 1:ncol(contingencyTable)) {\n",
    "        if (i != j) {\n",
    "          sumError = sumError + contingencyTable[i,j]\n",
    "        }\n",
    "        total = total + contingencyTable[i,j]\n",
    "      }\n",
    "    }\n",
    "    errorRate = c(errorRate, c(sumError/total))\n",
    "    \n",
    "  }\n",
    "  \n",
    "  meanPrecision = mean(errorRate)\n",
    "  robustesse_calculate = 0\n",
    "  \n",
    "  for (i in 1:length(errorRate)) {\n",
    "    robustesse_calculate = robustesse_calculate + (errorRate[i] - meanPrecision)*(errorRate[i] - meanPrecision)\n",
    "  }\n",
    "  #nombre de valeurs dans error rate est la même que le nombre de partitions\n",
    "  robustesse = robustesse_calculate/length(errorRate)\n",
    "  \n",
    "  if (metric == 1) {\n",
    "    return(robustesse)\n",
    "  } else {\n",
    "    return(mean(errorRate))\n",
    "  }\n",
    "  \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "validationCroiseeLDA = function(data, partitions, metric) {\n",
    "  errorRate = c()\n",
    "  #on mélange les données\n",
    "  randomData = data[sample(nrow(data)),]\n",
    "  #list\n",
    "  setPartitions = split(randomData, 1:partitions)\n",
    "  for (i in 1:(partitions)) {\n",
    "    tempSetPartitions = setPartitions\n",
    "    currentTestData = setPartitions[[i]]\n",
    "    currentModalDataList = tempSetPartitions[-i]\n",
    "    #fusion dataframe\n",
    "    currentModalData = rbind.data.frame(currentModalDataList[[1]], currentModalDataList[[2]])\n",
    "    \n",
    "    for (j in 3:(partitions-1)) {\n",
    "      currentModalData = rbind.data.frame(currentModalData, currentModalDataList[[j]])\n",
    "    }\n",
    "    \n",
    "    numOfLinesTestCurrentModalData = as.integer(length(currentModalData)*0.2)\n",
    "    numOflinesModalCurrentModalData = as.integer(length(currentModalData)*0.8)\n",
    "    \n",
    "    testData_step2 = currentModalData[1:numOfLinesTestCurrentModalData,]\n",
    "    modalData_step2 = currentModalData[numOfLinesTestCurrentModalData+1:numOflinesModalCurrentModalData,]\n",
    "    \n",
    "    #on calcule la précision (le taux d'erreurs)\n",
    "    tree = lda(X10~.,modalData_step2)\n",
    "    prediction = predict(tree, testData_step2, type=\"class\")\n",
    "    #utiliser predict pour trouver le taux d'erreur entre data et predict puis utiliser table\n",
    "    contingencyTable = table(testData_step2$X10, prediction$class)\n",
    "    \n",
    "    total = 0\n",
    "    sumError = 0\n",
    "    for (i in 1:nrow(contingencyTable)) {\n",
    "      for (j in 1:ncol(contingencyTable)) {\n",
    "        if (i != j) {\n",
    "          sumError = sumError + contingencyTable[i,j]\n",
    "        }\n",
    "        total = total + contingencyTable[i,j]\n",
    "      }\n",
    "    }\n",
    "    errorRate = c(errorRate, c(sumError/total))\n",
    "    \n",
    "  }\n",
    "  \n",
    "  meanPrecision = mean(errorRate)\n",
    "  robustesse_calculate = 0\n",
    "  \n",
    "  for (i in 1:length(errorRate)) {\n",
    "    robustesse_calculate = robustesse_calculate + (errorRate[i] - meanPrecision)*(errorRate[i] - meanPrecision)\n",
    "  }\n",
    "  #nombre de valeurs dans error rate est la même que le nombre de partitions\n",
    "  robustesse = robustesse_calculate/length(errorRate)\n",
    "  \n",
    "  if (metric == 1) {\n",
    "    return(robustesse)\n",
    "  } else {\n",
    "    return(mean(errorRate))\n",
    "  }\n",
    "  \n",
    "}\n",
    "\n",
    "\n",
    "#appel de fonction validationCroisee défini précédemment\n",
    "#en paramètre k = le nombre de répétition\n",
    "validationCroiseeRepetee = function (data, partitions, k) {\n",
    "  robustesseMean = 0\n",
    "  errorRateMean = 0\n",
    "  \n",
    "  for (i in 1:k) {\n",
    "    robustesseMean = robustesseMean + validationCroiseeRPART(data, partitions, 1)\n",
    "    errorRateMean = errorRateMean + validationCroiseeRPART(data, partitions, 0)\n",
    "  }\n",
    "  \n",
    "  robustesseMean = robustesseMean/k\n",
    "  errorRateMean = errorRateMean/k\n",
    "  \n",
    "  return(c(robustesseMean, errorRateMean))\n",
    "  \n",
    "}\n",
    "\n",
    "#data = dataframe\n",
    "#partitions = nombre de partition où on va split le dataset\n",
    "validationCroiseeImpliquee = function(data, partitions) {\n",
    "  \n",
    "  errorRate = c()\n",
    "  #on mélange les données\n",
    "  randomData = data[sample(nrow(data)),]\n",
    "  #list\n",
    "  setPartitions = split(randomData, 1:partitions)\n",
    "  listErrorRate = c()\n",
    "  \n",
    "  for (i in 1:partitions) {\n",
    "    \n",
    "    errorRate = c()\n",
    "    \n",
    "    for (i in 1:partitions-1) {\n",
    " \n",
    "      tempSetPartitions = setPartitions\n",
    "      currentTestData = setPartitions[[i]]\n",
    "      currentModalDataList = tempSetPartitions[-i]\n",
    "      #fusion dataframe\n",
    "      currentModalData = rbind.data.frame(currentModalDataList[[1]], currentModalDataList[[2]])\n",
    "      \n",
    "      for (j in 3:(partitions-2)) {\n",
    "        currentModalData = rbind.data.frame(currentModalData, currentModalDataList[[j]])\n",
    "      }\n",
    "      \n",
    "      numOfLinesTestCurrentModalData = as.integer(length(currentModalData)*0.2)\n",
    "      numOflinesModalCurrentModalData = as.integer(length(currentModalData)*0.8)\n",
    "      \n",
    "      testData_step2 = currentModalData[1:numOfLinesTestCurrentModalData,]\n",
    "      modalData_step2 = currentModalData[numOfLinesTestCurrentModalData+1:numOflinesModalCurrentModalData,]\n",
    "      \n",
    "      #on calcule la précision (le taux d'erreurs)\n",
    "      tree = lda(X10~.,modalData_step2)\n",
    "      prediction = predict(tree, testData_step2, type=\"class\")\n",
    "      #utiliser predict pour trouver le taux d'erreur entre data et predict puis utiliser table\n",
    "      contingencyTable = table(testData_step2$X10, prediction$class)\n",
    "      \n",
    "      total = 0\n",
    "      sumError = 0\n",
    "      for (i in 1:nrow(contingencyTable)) {\n",
    "        for (j in 1:ncol(contingencyTable)) {\n",
    "          if (i != j) {\n",
    "            sumError = sumError + contingencyTable[i,j]\n",
    "          }\n",
    "          total = total + contingencyTable[i,j]\n",
    "        }\n",
    "      }\n",
    "      errorRate = c(errorRate, c(sumError/total))\n",
    "    }\n",
    "    \n",
    "    listErrorRate = c(c(listErrorRate), mean(errorRate))\n",
    "    \n",
    "  }\n",
    "  \n",
    "  return(listErrorRate)\n",
    "  \n",
    "}\n",
    "\n",
    "#appel de la fonction validationCroisee\n",
    "#en paramètre data: un dataframe\n",
    "leaveOneOut = function(data) {\n",
    "  numberOfrows = nrow(data)\n",
    "  return(c(validationCroiseeRPART(data, numberOfrows, 0), validationCroiseeRPART(data, numberOfrows, 1)))\n",
    "}\n",
    "\n",
    "\n",
    "#appel de tous les fonctions définies précédemment\n",
    "\n",
    "algorithmSelection = function(data, K) {\n",
    "  \n",
    "  validationCroiseeRPARTErrorRate = validationRepeteeLDA(data, K)\n",
    "  validationCroiseeLDAErrorRate = validationRepeteeRPART(data, K)\n",
    "  \n",
    "  if (validationCroiseeRPARTErrorRate > validationCroiseeLDAErrorRate) {\n",
    "    return(\"SOLUTION: LDA\")\n",
    "  } else {\n",
    "    return(\"SOLUTION: RPART\")\n",
    "  }\n",
    "  \n",
    "  return(\"ERROR\")\n",
    "}\n",
    "\n",
    "validationCroiseeGetModel = function(data, partitions, metric) {\n",
    "  errorRate = c()\n",
    "  #on m\\u{fffd}lange les donn\\u{fffd}es\n",
    "  randomData = data[sample(nrow(data)),]\n",
    "  #list\n",
    "  setPartitions = split(randomData, 1:partitions)\n",
    "  for (i in 1:(partitions)) {\n",
    "    tempSetPartitions = setPartitions\n",
    "    currentTestData = setPartitions[[i]]\n",
    "    currentModalDataList = tempSetPartitions[-i]\n",
    "    #fusion dataframe\n",
    "    currentModalData = rbind.data.frame(currentModalDataList[[1]], currentModalDataList[[2]])\n",
    "    \n",
    "    for (j in 3:(partitions-1)) {\n",
    "      currentModalData = rbind.data.frame(currentModalData, currentModalDataList[[j]])\n",
    "    }\n",
    "    \n",
    "    numOfLinesTestCurrentModalData = as.integer(length(currentModalData)*0.2)\n",
    "    numOflinesModalCurrentModalData = as.integer(length(currentModalData)*0.8)\n",
    "    \n",
    "    testData_step2 = currentModalData[1:numOfLinesTestCurrentModalData,]\n",
    "    modalData_step2 = currentModalData[numOfLinesTestCurrentModalData+1:numOflinesModalCurrentModalData,]\n",
    "    \n",
    "    #on calcule la pr\\u{fffd}cision (le taux d'erreurs)\n",
    "    tree = rpart(modalData_step2$X1~.,modalData_step2, method=\"class\")\n",
    "    prediction = predict(tree, testData_step2, type=\"class\")\n",
    "    #utiliser predict pour trouver le taux d'erreur entre data et predict puis utiliser table\n",
    "    contingencyTable = table(testData_step2$X1, prediction)\n",
    "    \n",
    "    total = 0\n",
    "    sumError = 0\n",
    "    for (i in 1:nrow(contingencyTable)) {\n",
    "      for (j in 1:ncol(contingencyTable)) {\n",
    "        if (i != j) {\n",
    "          sumError = sumError + contingencyTable[i,j]\n",
    "        }\n",
    "        total = total + contingencyTable[i,j]\n",
    "      }\n",
    "    }\n",
    "    errorRate = c(errorRate, c(sumError/total))\n",
    "    \n",
    "  }\n",
    "  \n",
    "  meanPrecision = mean(errorRate)\n",
    "  robustesse_calculate = 0\n",
    "  \n",
    "  for (i in 1:length(errorRate)) {\n",
    "    robustesse_calculate = robustesse_calculate + (errorRate[i] - meanPrecision)*(errorRate[i] - meanPrecision)\n",
    "  }\n",
    "  #nombre de valeurs dans error rate est la m\\u{fffd}me que le nombre de partitions\n",
    "  robustesse = robustesse_calculate/length(errorRate)\n",
    "  \n",
    "  if (mean(errorRate) <= 0.3) {\n",
    "    print(\"Error Rate < 0.3\")\n",
    "    print(mean(errorRate))\n",
    "    return(tree)\n",
    "  }else{\n",
    "    print(\"Error Rate > 0.3, WRONG MODEL\")\n",
    "    print(mean(errorRate))\n",
    "    return(0)\n",
    "  }\n",
    "}\n",
    "\n",
    "loopGetModel = function(data, partitions){\n",
    "  result = 0\n",
    "  while(result == 0){\n",
    "    print(\"generating new model ...\")\n",
    "    \n",
    "    #Variable cible : predictionCA\n",
    "    donneesAppr = data[ , -c(1,2,3,4,5,6,7,8,9)]\n",
    "    names(donneesAppr) = c(\"X1\",\"X2\",\"X3\",\"X4\",\"X5\",\"X6\",\"X7\",\"X8\",\"X9\",\"X10\",\"X11\",\"X12\",\"X13\",\"X14\",\"X15\",\"X16\",\"X17\",\"X18\",\"X19\",\"X20\",\"X21\",\"X22\",\"X23\",\"X24\",\"X25\",\"X26\",\"X27\",\"X28\",\"X29\",\"X30\",\"X31\")\n",
    "    listResult = validationCroiseeGetModel(donneesAppr, partitions, \"X10\")\n",
    "    result = listResult[[1]]\n",
    "  }\n",
    "  print(listResult)\n",
    "  \n",
    "  \n",
    "  donneesTest = test[ , -c(1,2,3,36,37,38,39)]\n",
    "  names(donneesTest) = c(\"X2\",\"X3\",\"X4\",\"X5\",\"X6\",\"X7\",\"X8\",\"X9\",\"X10\",\"X11\",\"X12\",\"X13\",\"X14\",\"X15\",\"X16\",\"X17\",\"X18\",\"X19\",\"X20\",\"X21\",\"X22\",\"X23\",\"X24\",\"X25\",\"X26\",\"X27\",\"X28\",\"X29\",\"X30\",\"X31\")\n",
    "  prediction = predict(listResult[[2]], donneesTest, type=\"class\")\n",
    "  print(prediction)\n",
    "\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
